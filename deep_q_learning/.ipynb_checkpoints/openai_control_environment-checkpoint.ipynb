{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import cv2\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "\n",
    "class DeepQNN:\n",
    "    '''\n",
    "    episodes - NUMBER OF GAMES\n",
    "    gamma - discount rate\n",
    "    epsilon - exploration rate\n",
    "    epsilon_decay - decrease the number of explorations\n",
    "    epsilon_min - lower epsilon\n",
    "    lr - learning rate\n",
    "    '''\n",
    "    def __init__(self, env, episodes = 5000 , gamma = 0.95, epsilon = 1, epsilon_decay=0.9, epsilon_min=0.05, lr=0.001, random_state=42):\n",
    "    \n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.lr = lr\n",
    "        self.random_state = random_state\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.env = env\n",
    "        self.batch_size = 75\n",
    "        self.episodes = episodes\n",
    "        self.model_params = None\n",
    "        \n",
    "        self.activation_fn = tf.nn.elu\n",
    "        self.weights_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        self.optimizer = tf.train.AdamOptimizer\n",
    "        \n",
    "        self._graph = None\n",
    "        self._session = None\n",
    "        self.training_op = None\n",
    "        self.model = None\n",
    "        self.init = None\n",
    "        self.saver = None\n",
    "        \n",
    "        # Memory used for replaying actions\n",
    "        '''\n",
    "        using this memory improve stability. NN tends to forget previous actions learned, so the memory\n",
    "        allows a esxperience replay\n",
    "        '''\n",
    "        self.memmory = deque()\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        self.build_dnn()\n",
    "        \n",
    "        self.episodes_scores = []\n",
    "            \n",
    "    def build_dnn(self):\n",
    "        #Reset Tensorflow Graph\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            n_conv_filters = 32\n",
    "\n",
    "            X = tf.placeholder(tf.float32, shape=(None, 160, 100, 1),name= 'state')\n",
    "            y = tf.placeholder(tf.float32, shape=(None), name='quality')\n",
    "            self._X, self._y = X, y\n",
    "            self.training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "            conv_one = tf.layers.conv2d(X,filters= 4, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv1\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_one = tf.layers.batch_normalization(conv_one, training=self.training, momentum=0.9)\n",
    "            #conv_one = tf.nn.relu(conv_one)\n",
    "            \n",
    "            conv_two = tf.layers.conv2d(conv_one, filters= 2, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv2\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_two = tf.layers.batch_normalization(conv_two, training=self.training, momentum=0.9)\n",
    "            #conv_two = tf.nn.relu(conv_two)\n",
    "            \n",
    "            conv_three = tf.layers.conv2d(conv_two ,filters= 2, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv3\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_three = tf.layers.batch_normalization(conv_three, training=self.training, momentum=0.9)\n",
    "            #conv_three = tf.nn.relu(conv_three)\n",
    "            \n",
    "            \n",
    "            conv_four = tf.layers.conv2d(conv_three ,filters= 2, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv4\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_four = tf.layers.batch_normalization(conv_four, training=self.training, momentum=0.9)\n",
    "            #conv_four = tf.nn.relu(conv_four)\n",
    "            \n",
    "            conv_five = tf.layers.conv2d(conv_four, filters= 2, kernel_size=4, strides=1,\n",
    "                                   padding= \"SAME\", name=\"conv5\"\n",
    "                                  ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_five = tf.layers.batch_normalization(conv_five, training=self.training, momentum=0.9)\n",
    "            #conv_five = tf.nn.relu(conv_five)\n",
    "            \n",
    "            conv_six = tf.layers.conv2d(conv_five, filters= 2, kernel_size=4, strides=1,\n",
    "                                   padding= \"SAME\", name=\"conv6\"\n",
    "                                  ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_six = tf.layers.batch_normalization(conv_six, training=self.training, momentum=0.9)\n",
    "            #conv_six = tf.nn.relu(conv_six)\n",
    "            \n",
    "            flat = tf.reshape(conv_five , shape=[-1, 2 * 160 * 100])\n",
    "            #with tf.name_scope(\"pool\"):\n",
    "            #    pool = tf.nn.max_pool(conv_two, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "            #   pool_flat = tf.reshape(pool, shape=[-1, n_conv_filters * 32 * 32])\n",
    "\n",
    "            with tf.name_scope(\"fc\"):\n",
    "                fc1 = tf.layers.dense(flat, 6, name=\"fc1\"\n",
    "                                      , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                #fc1 = tf.layers.batch_normalization(fc1, training=self.training, momentum=0.9)\n",
    "                #fc1 = tf.nn.elu(fc1)\n",
    "            \n",
    "                #fc1 = tf.layers.dropout(fc1, 0.5, training = self.training)\n",
    "                fc2 = tf.layers.dense(fc1, 6, activation=tf.nn.elu,name=\"fc2\"\n",
    "                                      ,kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                #fc2 = tf.layers.batch_normalization(fc2, training=self.training, momentum=0.9)\n",
    "                #fc2 = tf.nn.elu(fc2)\n",
    "            \n",
    "                #fc2 = tf.layers.dropout(fc2, 0.5, training = self.training)\n",
    "                \n",
    "                fc3 = tf.layers.dense(fc2, 6, activation=tf.nn.elu,name=\"fc3\"\n",
    "                                      ,kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                #fc3 = tf.layers.batch_normalization(fc3, training=self.training, momentum=0.9)\n",
    "                #fc3 = tf.nn.elu(fc3)\n",
    "                # Dense with linear activation function\n",
    "                self.model = tf.layers.dense(fc2, self.n_actions,name=\"fc4\"\n",
    "                                            ,kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                loss = tf.losses.huber_loss(self._y, self.model)\n",
    "                optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "                #loss = tf.losses.mean_squared_error(self._y, self.model)\n",
    "                #loss = tf.reduce_mean(tf.squared_difference(x=self.model,y=self._y))\n",
    "                #optimizer = tf.train.AdamOptimizer(0.001)\n",
    "                self.training_op = optimizer.minimize(loss, name = \"training\")\n",
    "\n",
    "            with tf.name_scope(\"init_and_save\"):\n",
    "                self.init = tf.global_variables_initializer()\n",
    "                self.saver = tf.train.Saver()\n",
    "            \n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "       \n",
    "            \n",
    "    def remember_transition(self,state, action, reward, new_state, end):\n",
    "        \n",
    "        self.memmory.append((state, action, reward, new_state, end))\n",
    "        \n",
    "    def minibatch_sample(self):\n",
    "        return random.sample(self.memmory, self.batch_size)\n",
    "    \n",
    "    def predict(self,state):\n",
    "        with self._session.as_default() as sess:\n",
    "            return self.model.eval(feed_dict={self._X: state, self.training:False})\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_actions)\n",
    "        predict = self.predict(state)[0]\n",
    "        return np.argmax(predict)\n",
    "\n",
    "    def experience_learing(self):\n",
    "\n",
    "        minibatch = random.sample(self.memmory, self.batch_size)\n",
    "        for state, action, reward, next_state, end in minibatch:\n",
    "            target = reward\n",
    "            if not end:\n",
    "                target = reward + self.gamma * np.amax(self.predict(next_state)[0])\n",
    "            target_f = self.predict(state)[0]\n",
    "            target_f[action] = target         \n",
    "\n",
    "            with self._session.as_default() as sess:\n",
    "                sess.run(self.training_op, feed_dict={self._X: state, self._y: target_f, self.training: True})\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        '''\n",
    "    \n",
    "        states = self.minibatch_sample()\n",
    "        inputs = np.zeros((self.batch_size, 64, 64, 1))\n",
    "        targets = np.zeros((self.batch_size, self.n_actions))\n",
    "        for i in range(len(states)):\n",
    "            state = states[i][0]\n",
    "            action = states[i][1] \n",
    "            reward = states[i][2]\n",
    "            new_state = states[i][3]\n",
    "            end = states[i][4]\n",
    "            # Bellman equation\n",
    "            inputs[i: i+1] = state\n",
    "            quality = reward + self.gamma * np.amax(self.predict(new_state)[0])\n",
    "            if end:\n",
    "                quality = reward\n",
    "            targets[i] = self.predict(state)\n",
    "            targets[i][action] = quality\n",
    "            \n",
    "        with self._session.as_default() as sess:\n",
    "            sess.run(self.training_op, feed_dict={self._X: inputs, self._y: targets, self.training: True})\n",
    "            \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "                \n",
    "    '''\n",
    "    def combine(self, current_frame, new_frame, pos):\n",
    "        \n",
    "        current_frame = cv2.cvtColor(np.asarray(current_frame), cv2.COLOR_BGR2GRAY)\n",
    "        #current_frame =  current_frame.reshape(current_frame.shape[0],current_frame.shape[1],1)\n",
    "        new_frame = cv2.cvtColor(np.asarray(new_frame), cv2.COLOR_BGR2GRAY)\n",
    "        #new_frame = new_frame.reshape(new_frame.shape[0],new_frame.shape[1],1)\n",
    "        \n",
    "        #comb = np.concatenate((new_frame, current_frame), axis=2)\n",
    "        comb = new_frame - current_frame \n",
    "        \n",
    "        pos = self.position(pos)\n",
    "        min_pos = pos - 50\n",
    "        max_pos = pos +50\n",
    "        if min_pos < 0:\n",
    "            min_pos = 0\n",
    "            max_pos = 100\n",
    "        if max_pos > 600:\n",
    "            min_pos = 500\n",
    "            max_pos = 600\n",
    "        \n",
    "        comb = comb[160:320,min_pos:max_pos]\n",
    "        #comb = cv2.resize(comb,(64,64))\n",
    "        #_, comb[:,:,0] = cv2.threshold(comb[:,:,0],200,255,cv2.THRESH_BINARY)\n",
    "        #_, comb[:,:,1] = cv2.threshold(comb[:,:,1],200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "        return comb.reshape(1,160,100,1)\n",
    "        \n",
    "        \n",
    "    def diff_frames(self, current, past):        \n",
    "        diff = cv2.cvtColor(np.asarray(current-past), cv2.COLOR_BGR2GRAY)\n",
    "        return diff\n",
    "    \n",
    "    def position(self,pos):\n",
    "        screen_width = 600\n",
    "        world_width = 2.4* 2\n",
    "        scale = screen_width / world_width\n",
    "        pos = int(pos * scale + screen_width / 2.0)\n",
    "        return pos\n",
    "        \n",
    "    def state_transformation(self, pos, img):\n",
    "        img = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY)\n",
    "        pos = self.position(pos)\n",
    "        min_pos = pos - 50\n",
    "        max_pos = pos +50\n",
    "        if min_pos < 0:\n",
    "            min_pos = 0\n",
    "            max_pos = 100\n",
    "        if max_pos > 600:\n",
    "            min_pos = 500\n",
    "            max_pos = 600\n",
    "       \n",
    "        img = img[160:320,min_pos:max_pos]\n",
    "        #img = cv2.resize(img,(64,64))\n",
    "        _, img = cv2.threshold(img,200,255,cv2.THRESH_BINARY)\n",
    "        return img.reshape(1,160,100,1)\n",
    "        \n",
    "    \n",
    "    def get_model_params(self):\n",
    "        gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "    def restore_model_params(self, model_params):\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\") for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n",
    "        \n",
    "    def train(self):\n",
    "        interactions = 500\n",
    "        state_size = self.env.observation_space.shape[0]\n",
    "        with self._session.as_default() as sess:\n",
    "            self.init.run()\n",
    "        end = False\n",
    "        max_iterations = 0\n",
    "        for e in range(self.episodes):\n",
    "            obs = self.env.reset()\n",
    "            state = self.env.render(mode='rgb_array')\n",
    "            #state = self.state_transformation(obs[0],state)\n",
    "            next_state = self.env.render(mode='rgb_array')\n",
    "            #next_state = self.state_transformation(0,next_state)\n",
    "            comb = self.combine(state, next_state, obs[0])\n",
    "            \n",
    "            #plt.figure()\n",
    "            #plt.imshow(comb[0,:,:,0], cmap='gray')\n",
    "            #plt.show()\n",
    "            \n",
    "            for iteration in range(500):\n",
    "                action = self.select_action(comb)  \n",
    "                obs, reward, end, _ = env.step(action)\n",
    "                extra_reward = 1.0/abs(obs[2]) + (1.0/abs(obs[3])) *0.5 + (1.0/abs(obs[1]))* 0.5\n",
    "                next_state  = self.env.render(mode='rgb_array')\n",
    "                next_comb = self.combine(state, next_state, obs[0])\n",
    "                #next_state = self.state_transformation(obs[0],next_state)\n",
    "                reward = reward + extra_reward\n",
    "                if end:\n",
    "                    reward = 0\n",
    "                self.remember_transition(comb, action, reward, next_comb, end)\n",
    "                state = next_state\n",
    "                comb = next_comb\n",
    "                if end:\n",
    "                    self.episodes_scores.append(iteration)\n",
    "                    plt.figure()\n",
    "                    plt.plot(range(len(self.episodes_scores)), self.episodes_scores)\n",
    "                    plt.show()\n",
    "                    print(\"Episode: %d/%d, score: %d\" % (e, self.episodes, iteration))\n",
    "                    if iteration > max_iterations:\n",
    "                        max_iterations = iteration \n",
    "                    break\n",
    "\n",
    "            if len(self.memmory) > self.batch_size:\n",
    "                self.experience_learing()\n",
    "    \n",
    "\n",
    "        print(\"Best Number of Iterations: %d\" % (max_iterations))\n",
    "        \n",
    "        with self._session.as_default() as sess:\n",
    "            self.saver.save(sess, \"./openai_convolution.ckpt\")  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-16 15:45:33,671] Making new env: CartPole-v1\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "q_dnn= DeepQNN(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0/5000, score: 10\n",
      "Episode: 1/5000, score: 14\n",
      "Episode: 2/5000, score: 15\n",
      "Episode: 3/5000, score: 29\n",
      "Episode: 4/5000, score: 10\n",
      "Episode: 5/5000, score: 34\n",
      "Episode: 6/5000, score: 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c14b0a067cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_dnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-dfb669223a05>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mextra_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0mnext_state\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mnext_comb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m#next_state = self.state_transformation(obs[0],next_state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/core.pyc\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/core.pyc\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/core.pyc\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/envs/classic_control/cartpole.pyc\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/envs/classic_control/rendering.pyc\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# In https://github.com/openai/gym-http-api/issues/2, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pyglet/image/__init__.pyc\u001b[0m in \u001b[0;36mget_image_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2088\u001b[0m         \u001b[0mglPixelStorei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_PACK_ALIGNMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m         glReadPixels(x, y, self.width, self.height, \n\u001b[0;32m-> 2090\u001b[0;31m                      self.gl_format, GL_UNSIGNED_BYTE, buffer)\n\u001b[0m\u001b[1;32m   2091\u001b[0m         \u001b[0mglPopClientAttrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pyglet/gl/lib.pyc\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "q_dnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12fc3d450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(q_dnn.episodes_scores)), q_dnn.episodes_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "\n",
    "class QNN:\n",
    "    '''\n",
    "    episodes - NUMBER OF GAMES\n",
    "    gamma - discount rate\n",
    "    epsilon - exploration rate\n",
    "    epsilon_decay - decrease the number of explorations\n",
    "    epsilon_min - lower epsilon\n",
    "    lr - learning rate\n",
    "    '''\n",
    "    def __init__(self, env, episodes = 5000 , gamma = 0.95, epsilon = 1, epsilon_decay=0.995, epsilon_min=0.05, lr=0.001, random_state=42):\n",
    "    \n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.lr = lr\n",
    "        self.random_state = random_state\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.env = env\n",
    "        self.batch_size = 50\n",
    "        self.episodes = episodes\n",
    "        self.model_params = None\n",
    "        \n",
    "        self.activation_fn = tf.nn.elu\n",
    "        self.weights_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        self.optimizer = tf.train.AdamOptimizer\n",
    "        \n",
    "        self._graph = None\n",
    "        self._session = None\n",
    "        self.training_op = None\n",
    "        self.model = None\n",
    "        self.init = None\n",
    "        self.saver = None\n",
    "        \n",
    "        # Memory used for replaying actions\n",
    "        '''\n",
    "        using this memory improve stability. NN tends to forget previous actions learned, so the memory\n",
    "        allows a esxperience replay\n",
    "        '''\n",
    "        self.memmory = deque()\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        self.build_dnn()\n",
    "            \n",
    "    def build_dnn(self):\n",
    "        #Reset Tensorflow Graph\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            X = tf.placeholder(tf.float32, shape=(None,4),name= 'state')\n",
    "            y = tf.placeholder(tf.float32, shape=(None), name='quality')\n",
    "            self._X, self._y = X, y\n",
    "            self.training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "            with tf.name_scope(\"fc\"):\n",
    "                fc1 = tf.layers.dense(X, 12, activation=tf.nn.relu, name=\"fc1\")\n",
    "                #fc1_dropout = tf.layers.dropout(fc1, 0.5, training = self.training)\n",
    "                fc2 = tf.layers.dense(fc1, 12, activation=tf.nn.relu,name=\"fc2\")\n",
    "                #fc2_dropout = tf.layers.dropout(fc2, 0.5, training = self.training)\n",
    "                # Dense with linear activation function\n",
    "                self.model = tf.layers.dense(fc2, self.n_actions,name=\"fc3\")\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                loss = tf.losses.mean_squared_error(self._y, self.model)\n",
    "                optimizer = tf.train.AdamOptimizer(0.001)\n",
    "                self.training_op = optimizer.minimize(loss, name = \"training\")\n",
    "\n",
    "            with tf.name_scope(\"init_and_save\"):\n",
    "                self.init = tf.global_variables_initializer()\n",
    "                self.saver = tf.train.Saver()\n",
    "            \n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "       \n",
    "            \n",
    "    def remember_transition(self,state, action, reward, new_state, end):\n",
    "        \n",
    "        self.memmory.append((state, action, reward, new_state, end))\n",
    "        \n",
    "    def minibatch_sample(self):\n",
    "        return random.sample(self.memmory, self.batch_size)\n",
    "    \n",
    "    def predict(self,state):\n",
    "        with self._session.as_default() as sess:\n",
    "            return self.model.eval(feed_dict={self._X: state.reshape(1,4), self.training:False})\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_actions)\n",
    "        predict = self.predict(state)[0]\n",
    "        #print('Action ',predict)\n",
    "        #print('Predicted ',np.argmax(predict))\n",
    "        return np.argmax(predict)\n",
    "\n",
    "    def experience_learing(self):\n",
    "        \n",
    "        minibatch = random.sample(self.memmory, self.batch_size)\n",
    "        for state, action, reward, next_state, end in minibatch:\n",
    "            target = reward\n",
    "            if not end:\n",
    "                target = reward + self.gamma * np.amax(self.predict(next_state)[0])\n",
    "            target_f = self.predict(state)[0]\n",
    "            target_f[action] = target         \n",
    "\n",
    "            with self._session.as_default() as sess:\n",
    "                sess.run(self.training_op, feed_dict={self._X: state.reshape(1,4), self._y: target_f, self.training: True})\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "        '''\n",
    "        states = self.minibatch_sample()\n",
    "        inputs = np.zeros((self.batch_size,4))\n",
    "        targets = np.zeros((self.batch_size, self.n_actions))\n",
    "        for i in range(len(states)):\n",
    "            state = states[i][0]\n",
    "            action = states[i][1] \n",
    "            reward = states[i][2]\n",
    "            new_state = states[i][3]\n",
    "            end = states[i][4]\n",
    "            # Bellman equation\n",
    "            inputs[i] = state\n",
    "            quality = reward + self.gamma * np.amax(self.predict(new_state)[0])\n",
    "            if end:\n",
    "                quality = reward\n",
    "            targets[i] = self.predict(state)\n",
    "            targets[i][action] = quality\n",
    "            \n",
    "        with self._session.as_default() as sess:\n",
    "            sess.run(self.training_op, feed_dict={self._X: inputs, self._y: targets, self.training: True})\n",
    "            \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        '''        \n",
    "        \n",
    "         \n",
    "\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "    def restore_model_params(self, model_params):\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\") for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        interactions = 2000\n",
    "        state_size = self.env.observation_space.shape[0]\n",
    "        with self._session.as_default() as sess:\n",
    "            self.init.run()\n",
    "        end = False\n",
    "        max_iterations = 0\n",
    "        for e in range(self.episodes):\n",
    "            state = self.env.reset().reshape(1, self.env.observation_space.shape[0])\n",
    "             \n",
    "            for iteration in range(interactions):\n",
    "                action = self.select_action(state) \n",
    "                next_state, reward, end, _ = env.step(action)\n",
    "                #extra_reward = 1.0/abs(next_state[2]) + 1.0/abs(next_state[3])\n",
    "                reward = reward #+ extra_reward\n",
    "                self.remember_transition(state, action, reward, next_state, end)\n",
    "                state = next_state \n",
    "                if end:\n",
    "                    print(\"Episode: %d/%d, score: %d\" % (e, self.episodes, iteration))\n",
    "                    if iteration > max_iterations:\n",
    "                        max_iterations = iteration \n",
    "                    break\n",
    "\n",
    "            if len(self.memmory) > self.batch_size:\n",
    "                self.experience_learing()\n",
    "    \n",
    "\n",
    "        print(\"Best Number of Iterations: %d\" % (max_iterations))\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            self.saver.save(sess, \"./openai.ckpt\")  \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-11 00:24:47,591] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0/5000, score: 13\n",
      "Episode: 1/5000, score: 11\n",
      "Episode: 2/5000, score: 47\n",
      "Episode: 3/5000, score: 25\n",
      "Episode: 4/5000, score: 16\n",
      "Episode: 5/5000, score: 18\n",
      "Episode: 6/5000, score: 10\n",
      "Episode: 7/5000, score: 11\n",
      "Episode: 8/5000, score: 18\n",
      "Episode: 9/5000, score: 9\n",
      "Episode: 10/5000, score: 48\n",
      "Episode: 11/5000, score: 46\n",
      "Episode: 12/5000, score: 14\n",
      "Episode: 13/5000, score: 13\n",
      "Episode: 14/5000, score: 24\n",
      "Episode: 15/5000, score: 21\n",
      "Episode: 16/5000, score: 15\n",
      "Episode: 17/5000, score: 32\n",
      "Episode: 18/5000, score: 29\n",
      "Episode: 19/5000, score: 10\n",
      "Episode: 20/5000, score: 26\n",
      "Episode: 21/5000, score: 15\n",
      "Episode: 22/5000, score: 54\n",
      "Episode: 23/5000, score: 55\n",
      "Episode: 24/5000, score: 11\n",
      "Episode: 25/5000, score: 18\n",
      "Episode: 26/5000, score: 24\n",
      "Episode: 27/5000, score: 37\n",
      "Episode: 28/5000, score: 29\n",
      "Episode: 29/5000, score: 17\n",
      "Episode: 30/5000, score: 39\n",
      "Episode: 31/5000, score: 10\n",
      "Episode: 32/5000, score: 18\n",
      "Episode: 33/5000, score: 39\n",
      "Episode: 34/5000, score: 19\n",
      "Episode: 35/5000, score: 14\n",
      "Episode: 36/5000, score: 18\n",
      "Episode: 37/5000, score: 12\n",
      "Episode: 38/5000, score: 26\n",
      "Episode: 39/5000, score: 20\n",
      "Episode: 40/5000, score: 15\n",
      "Episode: 41/5000, score: 7\n",
      "Episode: 42/5000, score: 7\n",
      "Episode: 43/5000, score: 19\n",
      "Episode: 44/5000, score: 9\n",
      "Episode: 45/5000, score: 15\n",
      "Episode: 46/5000, score: 11\n",
      "Episode: 47/5000, score: 19\n",
      "Episode: 48/5000, score: 25\n",
      "Episode: 49/5000, score: 12\n",
      "Episode: 50/5000, score: 10\n",
      "Episode: 51/5000, score: 13\n",
      "Episode: 52/5000, score: 10\n",
      "Episode: 53/5000, score: 21\n",
      "Episode: 54/5000, score: 20\n",
      "Episode: 55/5000, score: 10\n",
      "Episode: 56/5000, score: 16\n",
      "Episode: 57/5000, score: 17\n",
      "Episode: 58/5000, score: 17\n",
      "Episode: 59/5000, score: 38\n",
      "Episode: 60/5000, score: 12\n",
      "Episode: 61/5000, score: 30\n",
      "Episode: 62/5000, score: 13\n",
      "Episode: 63/5000, score: 8\n",
      "Episode: 64/5000, score: 12\n",
      "Episode: 65/5000, score: 14\n",
      "Episode: 66/5000, score: 18\n",
      "Episode: 67/5000, score: 15\n",
      "Episode: 68/5000, score: 17\n",
      "Episode: 69/5000, score: 13\n",
      "Episode: 70/5000, score: 10\n",
      "Episode: 71/5000, score: 10\n",
      "Episode: 72/5000, score: 17\n",
      "Episode: 73/5000, score: 16\n",
      "Episode: 74/5000, score: 14\n",
      "Episode: 75/5000, score: 33\n",
      "Episode: 76/5000, score: 10\n",
      "Episode: 77/5000, score: 21\n",
      "Episode: 78/5000, score: 18\n",
      "Episode: 79/5000, score: 16\n",
      "Episode: 80/5000, score: 14\n",
      "Episode: 81/5000, score: 19\n",
      "Episode: 82/5000, score: 18\n",
      "Episode: 83/5000, score: 21\n",
      "Episode: 84/5000, score: 12\n",
      "Episode: 85/5000, score: 10\n",
      "Episode: 86/5000, score: 11\n",
      "Episode: 87/5000, score: 48\n",
      "Episode: 88/5000, score: 13\n",
      "Episode: 89/5000, score: 10\n",
      "Episode: 90/5000, score: 12\n",
      "Episode: 91/5000, score: 17\n",
      "Episode: 92/5000, score: 13\n",
      "Episode: 93/5000, score: 13\n",
      "Episode: 94/5000, score: 15\n",
      "Episode: 95/5000, score: 38\n",
      "Episode: 96/5000, score: 28\n",
      "Episode: 97/5000, score: 14\n",
      "Episode: 98/5000, score: 28\n",
      "Episode: 99/5000, score: 20\n",
      "Episode: 100/5000, score: 11\n",
      "Episode: 101/5000, score: 10\n",
      "Episode: 102/5000, score: 16\n",
      "Episode: 103/5000, score: 30\n",
      "Episode: 104/5000, score: 22\n",
      "Episode: 105/5000, score: 44\n",
      "Episode: 106/5000, score: 11\n",
      "Episode: 107/5000, score: 9\n",
      "Episode: 108/5000, score: 16\n",
      "Episode: 109/5000, score: 11\n",
      "Episode: 110/5000, score: 13\n",
      "Episode: 111/5000, score: 12\n",
      "Episode: 112/5000, score: 15\n",
      "Episode: 113/5000, score: 18\n",
      "Episode: 114/5000, score: 16\n",
      "Episode: 115/5000, score: 31\n",
      "Episode: 116/5000, score: 27\n",
      "Episode: 117/5000, score: 83\n",
      "Episode: 118/5000, score: 41\n",
      "Episode: 119/5000, score: 26\n",
      "Episode: 120/5000, score: 17\n",
      "Episode: 121/5000, score: 56\n",
      "Episode: 122/5000, score: 14\n",
      "Episode: 123/5000, score: 36\n",
      "Episode: 124/5000, score: 33\n",
      "Episode: 125/5000, score: 17\n",
      "Episode: 126/5000, score: 19\n",
      "Episode: 127/5000, score: 17\n",
      "Episode: 128/5000, score: 24\n",
      "Episode: 129/5000, score: 15\n",
      "Episode: 130/5000, score: 28\n",
      "Episode: 131/5000, score: 13\n",
      "Episode: 132/5000, score: 30\n",
      "Episode: 133/5000, score: 52\n",
      "Episode: 134/5000, score: 52\n",
      "Episode: 135/5000, score: 27\n",
      "Episode: 136/5000, score: 20\n",
      "Episode: 137/5000, score: 14\n",
      "Episode: 138/5000, score: 15\n",
      "Episode: 139/5000, score: 30\n",
      "Episode: 140/5000, score: 20\n",
      "Episode: 141/5000, score: 34\n",
      "Episode: 142/5000, score: 52\n",
      "Episode: 143/5000, score: 38\n",
      "Episode: 144/5000, score: 24\n",
      "Episode: 145/5000, score: 58\n",
      "Episode: 146/5000, score: 92\n",
      "Episode: 147/5000, score: 26\n",
      "Episode: 148/5000, score: 21\n",
      "Episode: 149/5000, score: 17\n",
      "Episode: 150/5000, score: 26\n",
      "Episode: 151/5000, score: 17\n",
      "Episode: 152/5000, score: 8\n",
      "Episode: 153/5000, score: 14\n",
      "Episode: 154/5000, score: 11\n",
      "Episode: 155/5000, score: 16\n",
      "Episode: 156/5000, score: 21\n",
      "Episode: 157/5000, score: 18\n",
      "Episode: 158/5000, score: 16\n",
      "Episode: 159/5000, score: 41\n",
      "Episode: 160/5000, score: 24\n",
      "Episode: 161/5000, score: 22\n",
      "Episode: 162/5000, score: 12\n",
      "Episode: 163/5000, score: 9\n",
      "Episode: 164/5000, score: 26\n",
      "Episode: 165/5000, score: 18\n",
      "Episode: 166/5000, score: 78\n",
      "Episode: 167/5000, score: 93\n",
      "Episode: 168/5000, score: 58\n",
      "Episode: 169/5000, score: 63\n",
      "Episode: 170/5000, score: 23\n",
      "Episode: 171/5000, score: 23\n",
      "Episode: 172/5000, score: 17\n",
      "Episode: 173/5000, score: 10\n",
      "Episode: 174/5000, score: 18\n",
      "Episode: 175/5000, score: 18\n",
      "Episode: 176/5000, score: 13\n",
      "Episode: 177/5000, score: 10\n",
      "Episode: 178/5000, score: 12\n",
      "Episode: 179/5000, score: 160\n",
      "Episode: 180/5000, score: 40\n",
      "Episode: 181/5000, score: 45\n",
      "Episode: 182/5000, score: 22\n",
      "Episode: 183/5000, score: 21\n",
      "Episode: 184/5000, score: 13\n",
      "Episode: 185/5000, score: 10\n",
      "Episode: 186/5000, score: 51\n",
      "Episode: 187/5000, score: 21\n",
      "Episode: 188/5000, score: 34\n",
      "Episode: 189/5000, score: 58\n",
      "Episode: 190/5000, score: 62\n",
      "Episode: 191/5000, score: 26\n",
      "Episode: 192/5000, score: 21\n",
      "Episode: 193/5000, score: 29\n",
      "Episode: 194/5000, score: 29\n",
      "Episode: 195/5000, score: 22\n",
      "Episode: 196/5000, score: 13\n",
      "Episode: 197/5000, score: 33\n",
      "Episode: 198/5000, score: 20\n",
      "Episode: 199/5000, score: 48\n",
      "Episode: 200/5000, score: 29\n",
      "Episode: 201/5000, score: 35\n",
      "Episode: 202/5000, score: 32\n",
      "Episode: 203/5000, score: 50\n",
      "Episode: 204/5000, score: 54\n",
      "Episode: 205/5000, score: 44\n",
      "Episode: 206/5000, score: 38\n",
      "Episode: 207/5000, score: 20\n",
      "Episode: 208/5000, score: 36\n",
      "Episode: 209/5000, score: 31\n",
      "Episode: 210/5000, score: 25\n",
      "Episode: 211/5000, score: 38\n",
      "Episode: 212/5000, score: 44\n",
      "Episode: 213/5000, score: 50\n",
      "Episode: 214/5000, score: 52\n",
      "Episode: 215/5000, score: 42\n",
      "Episode: 216/5000, score: 27\n",
      "Episode: 217/5000, score: 62\n",
      "Episode: 218/5000, score: 46\n",
      "Episode: 219/5000, score: 43\n",
      "Episode: 220/5000, score: 25\n",
      "Episode: 221/5000, score: 37\n",
      "Episode: 222/5000, score: 54\n",
      "Episode: 223/5000, score: 28\n",
      "Episode: 224/5000, score: 31\n",
      "Episode: 225/5000, score: 19\n",
      "Episode: 226/5000, score: 49\n",
      "Episode: 227/5000, score: 57\n",
      "Episode: 228/5000, score: 31\n",
      "Episode: 229/5000, score: 61\n",
      "Episode: 230/5000, score: 20\n",
      "Episode: 231/5000, score: 21\n",
      "Episode: 232/5000, score: 17\n",
      "Episode: 233/5000, score: 58\n",
      "Episode: 234/5000, score: 25\n",
      "Episode: 235/5000, score: 30\n",
      "Episode: 236/5000, score: 69\n",
      "Episode: 237/5000, score: 32\n",
      "Episode: 238/5000, score: 18\n",
      "Episode: 239/5000, score: 30\n",
      "Episode: 240/5000, score: 15\n",
      "Episode: 241/5000, score: 17\n",
      "Episode: 242/5000, score: 39\n",
      "Episode: 243/5000, score: 15\n",
      "Episode: 244/5000, score: 14\n",
      "Episode: 245/5000, score: 18\n",
      "Episode: 246/5000, score: 20\n",
      "Episode: 247/5000, score: 43\n",
      "Episode: 248/5000, score: 43\n",
      "Episode: 249/5000, score: 31\n",
      "Episode: 250/5000, score: 25\n",
      "Episode: 251/5000, score: 21\n",
      "Episode: 252/5000, score: 44\n",
      "Episode: 253/5000, score: 81\n",
      "Episode: 254/5000, score: 73\n",
      "Episode: 255/5000, score: 46\n",
      "Episode: 256/5000, score: 32\n",
      "Episode: 257/5000, score: 74\n",
      "Episode: 258/5000, score: 89\n",
      "Episode: 259/5000, score: 20\n",
      "Episode: 260/5000, score: 34\n",
      "Episode: 261/5000, score: 30\n",
      "Episode: 262/5000, score: 25\n",
      "Episode: 263/5000, score: 47\n",
      "Episode: 264/5000, score: 37\n",
      "Episode: 265/5000, score: 127\n",
      "Episode: 266/5000, score: 32\n",
      "Episode: 267/5000, score: 30\n",
      "Episode: 268/5000, score: 21\n",
      "Episode: 269/5000, score: 36\n",
      "Episode: 270/5000, score: 28\n",
      "Episode: 271/5000, score: 16\n",
      "Episode: 272/5000, score: 30\n",
      "Episode: 273/5000, score: 128\n",
      "Episode: 274/5000, score: 32\n",
      "Episode: 275/5000, score: 30\n",
      "Episode: 276/5000, score: 83\n",
      "Episode: 277/5000, score: 49\n",
      "Episode: 278/5000, score: 103\n",
      "Episode: 279/5000, score: 76\n",
      "Episode: 280/5000, score: 95\n",
      "Episode: 281/5000, score: 46\n",
      "Episode: 282/5000, score: 46\n",
      "Episode: 283/5000, score: 37\n",
      "Episode: 284/5000, score: 44\n",
      "Episode: 285/5000, score: 38\n",
      "Episode: 286/5000, score: 23\n",
      "Episode: 287/5000, score: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 288/5000, score: 70\n",
      "Episode: 289/5000, score: 33\n",
      "Episode: 290/5000, score: 89\n",
      "Episode: 291/5000, score: 30\n",
      "Episode: 292/5000, score: 43\n",
      "Episode: 293/5000, score: 34\n",
      "Episode: 294/5000, score: 29\n",
      "Episode: 295/5000, score: 65\n",
      "Episode: 296/5000, score: 59\n",
      "Episode: 297/5000, score: 42\n",
      "Episode: 298/5000, score: 42\n",
      "Episode: 299/5000, score: 73\n",
      "Episode: 300/5000, score: 185\n",
      "Episode: 301/5000, score: 102\n",
      "Episode: 302/5000, score: 48\n",
      "Episode: 303/5000, score: 32\n",
      "Episode: 304/5000, score: 42\n",
      "Episode: 305/5000, score: 156\n",
      "Episode: 306/5000, score: 51\n",
      "Episode: 307/5000, score: 52\n",
      "Episode: 308/5000, score: 81\n",
      "Episode: 309/5000, score: 147\n",
      "Episode: 310/5000, score: 40\n",
      "Episode: 311/5000, score: 43\n",
      "Episode: 312/5000, score: 50\n",
      "Episode: 313/5000, score: 23\n",
      "Episode: 314/5000, score: 43\n",
      "Episode: 315/5000, score: 39\n",
      "Episode: 316/5000, score: 43\n",
      "Episode: 317/5000, score: 123\n",
      "Episode: 318/5000, score: 66\n",
      "Episode: 319/5000, score: 51\n",
      "Episode: 320/5000, score: 57\n",
      "Episode: 321/5000, score: 40\n",
      "Episode: 322/5000, score: 26\n",
      "Episode: 323/5000, score: 33\n",
      "Episode: 324/5000, score: 52\n",
      "Episode: 325/5000, score: 100\n",
      "Episode: 326/5000, score: 58\n",
      "Episode: 327/5000, score: 78\n",
      "Episode: 328/5000, score: 52\n",
      "Episode: 329/5000, score: 58\n",
      "Episode: 330/5000, score: 44\n",
      "Episode: 331/5000, score: 115\n",
      "Episode: 332/5000, score: 64\n",
      "Episode: 333/5000, score: 43\n",
      "Episode: 334/5000, score: 73\n",
      "Episode: 335/5000, score: 78\n",
      "Episode: 336/5000, score: 114\n",
      "Episode: 337/5000, score: 73\n",
      "Episode: 338/5000, score: 40\n",
      "Episode: 339/5000, score: 70\n",
      "Episode: 340/5000, score: 105\n",
      "Episode: 341/5000, score: 150\n",
      "Episode: 342/5000, score: 82\n",
      "Episode: 343/5000, score: 46\n",
      "Episode: 344/5000, score: 80\n",
      "Episode: 345/5000, score: 113\n",
      "Episode: 346/5000, score: 111\n",
      "Episode: 347/5000, score: 70\n",
      "Episode: 348/5000, score: 87\n",
      "Episode: 349/5000, score: 242\n",
      "Episode: 350/5000, score: 80\n",
      "Episode: 351/5000, score: 29\n",
      "Episode: 352/5000, score: 45\n",
      "Episode: 353/5000, score: 31\n",
      "Episode: 354/5000, score: 35\n",
      "Episode: 355/5000, score: 54\n",
      "Episode: 356/5000, score: 45\n",
      "Episode: 357/5000, score: 79\n",
      "Episode: 358/5000, score: 65\n",
      "Episode: 359/5000, score: 52\n",
      "Episode: 360/5000, score: 32\n",
      "Episode: 361/5000, score: 53\n",
      "Episode: 362/5000, score: 130\n",
      "Episode: 363/5000, score: 68\n",
      "Episode: 364/5000, score: 61\n",
      "Episode: 365/5000, score: 97\n",
      "Episode: 366/5000, score: 85\n",
      "Episode: 367/5000, score: 69\n",
      "Episode: 368/5000, score: 69\n",
      "Episode: 369/5000, score: 52\n",
      "Episode: 370/5000, score: 49\n",
      "Episode: 371/5000, score: 61\n",
      "Episode: 372/5000, score: 49\n",
      "Episode: 373/5000, score: 61\n",
      "Episode: 374/5000, score: 31\n",
      "Episode: 375/5000, score: 48\n",
      "Episode: 376/5000, score: 59\n",
      "Episode: 377/5000, score: 60\n",
      "Episode: 378/5000, score: 53\n",
      "Episode: 379/5000, score: 88\n",
      "Episode: 380/5000, score: 74\n",
      "Episode: 381/5000, score: 56\n",
      "Episode: 382/5000, score: 88\n",
      "Episode: 383/5000, score: 47\n",
      "Episode: 384/5000, score: 66\n",
      "Episode: 385/5000, score: 46\n",
      "Episode: 386/5000, score: 29\n",
      "Episode: 387/5000, score: 25\n",
      "Episode: 388/5000, score: 27\n",
      "Episode: 389/5000, score: 29\n",
      "Episode: 390/5000, score: 21\n",
      "Episode: 391/5000, score: 33\n",
      "Episode: 392/5000, score: 57\n",
      "Episode: 393/5000, score: 69\n",
      "Episode: 394/5000, score: 85\n",
      "Episode: 395/5000, score: 87\n",
      "Episode: 396/5000, score: 334\n",
      "Episode: 397/5000, score: 170\n",
      "Episode: 398/5000, score: 92\n",
      "Episode: 399/5000, score: 136\n",
      "Episode: 400/5000, score: 73\n",
      "Episode: 401/5000, score: 46\n",
      "Episode: 402/5000, score: 69\n",
      "Episode: 403/5000, score: 171\n",
      "Episode: 404/5000, score: 231\n",
      "Episode: 405/5000, score: 138\n",
      "Episode: 406/5000, score: 108\n",
      "Episode: 407/5000, score: 149\n",
      "Episode: 408/5000, score: 179\n",
      "Episode: 409/5000, score: 85\n",
      "Episode: 410/5000, score: 100\n",
      "Episode: 411/5000, score: 130\n",
      "Episode: 412/5000, score: 104\n",
      "Episode: 413/5000, score: 95\n",
      "Episode: 414/5000, score: 173\n",
      "Episode: 415/5000, score: 138\n",
      "Episode: 416/5000, score: 98\n",
      "Episode: 417/5000, score: 144\n",
      "Episode: 418/5000, score: 168\n",
      "Episode: 419/5000, score: 91\n",
      "Episode: 420/5000, score: 96\n",
      "Episode: 421/5000, score: 127\n",
      "Episode: 422/5000, score: 169\n",
      "Episode: 423/5000, score: 167\n",
      "Episode: 424/5000, score: 247\n",
      "Episode: 425/5000, score: 109\n",
      "Episode: 426/5000, score: 270\n",
      "Episode: 427/5000, score: 242\n",
      "Episode: 428/5000, score: 111\n",
      "Episode: 429/5000, score: 131\n",
      "Episode: 430/5000, score: 96\n",
      "Episode: 431/5000, score: 144\n",
      "Episode: 432/5000, score: 156\n",
      "Episode: 433/5000, score: 375\n",
      "Episode: 434/5000, score: 229\n",
      "Episode: 435/5000, score: 137\n",
      "Episode: 436/5000, score: 180\n",
      "Episode: 437/5000, score: 104\n",
      "Episode: 438/5000, score: 201\n",
      "Episode: 439/5000, score: 52\n",
      "Episode: 440/5000, score: 123\n",
      "Episode: 441/5000, score: 195\n",
      "Episode: 442/5000, score: 132\n",
      "Episode: 443/5000, score: 218\n",
      "Episode: 444/5000, score: 411\n",
      "Episode: 445/5000, score: 245\n",
      "Episode: 446/5000, score: 127\n",
      "Episode: 447/5000, score: 101\n",
      "Episode: 448/5000, score: 100\n",
      "Episode: 449/5000, score: 138\n",
      "Episode: 450/5000, score: 130\n",
      "Episode: 451/5000, score: 75\n",
      "Episode: 452/5000, score: 73\n",
      "Episode: 453/5000, score: 103\n",
      "Episode: 454/5000, score: 184\n",
      "Episode: 455/5000, score: 48\n",
      "Episode: 456/5000, score: 36\n",
      "Episode: 457/5000, score: 108\n",
      "Episode: 458/5000, score: 89\n",
      "Episode: 459/5000, score: 90\n",
      "Episode: 460/5000, score: 132\n",
      "Episode: 461/5000, score: 144\n",
      "Episode: 462/5000, score: 96\n",
      "Episode: 463/5000, score: 39\n",
      "Episode: 464/5000, score: 46\n",
      "Episode: 465/5000, score: 80\n",
      "Episode: 466/5000, score: 81\n",
      "Episode: 467/5000, score: 75\n",
      "Episode: 468/5000, score: 79\n",
      "Episode: 469/5000, score: 345\n",
      "Episode: 470/5000, score: 131\n",
      "Episode: 471/5000, score: 182\n",
      "Episode: 472/5000, score: 154\n",
      "Episode: 473/5000, score: 111\n",
      "Episode: 474/5000, score: 108\n",
      "Episode: 475/5000, score: 154\n",
      "Episode: 476/5000, score: 133\n",
      "Episode: 477/5000, score: 164\n",
      "Episode: 478/5000, score: 499\n",
      "Episode: 479/5000, score: 122\n",
      "Episode: 480/5000, score: 67\n",
      "Episode: 481/5000, score: 82\n",
      "Episode: 482/5000, score: 78\n",
      "Episode: 483/5000, score: 345\n",
      "Episode: 484/5000, score: 92\n",
      "Episode: 485/5000, score: 59\n",
      "Episode: 486/5000, score: 16\n",
      "Episode: 487/5000, score: 120\n",
      "Episode: 488/5000, score: 102\n",
      "Episode: 489/5000, score: 301\n",
      "Episode: 490/5000, score: 350\n",
      "Episode: 491/5000, score: 108\n",
      "Episode: 492/5000, score: 168\n",
      "Episode: 493/5000, score: 210\n",
      "Episode: 494/5000, score: 152\n",
      "Episode: 495/5000, score: 158\n",
      "Episode: 496/5000, score: 186\n",
      "Episode: 497/5000, score: 462\n",
      "Episode: 498/5000, score: 125\n",
      "Episode: 499/5000, score: 132\n",
      "Episode: 500/5000, score: 130\n",
      "Episode: 501/5000, score: 95\n",
      "Episode: 502/5000, score: 106\n",
      "Episode: 503/5000, score: 91\n",
      "Episode: 504/5000, score: 91\n",
      "Episode: 505/5000, score: 157\n",
      "Episode: 506/5000, score: 115\n",
      "Episode: 507/5000, score: 113\n",
      "Episode: 508/5000, score: 109\n",
      "Episode: 509/5000, score: 124\n",
      "Episode: 510/5000, score: 138\n",
      "Episode: 511/5000, score: 110\n",
      "Episode: 512/5000, score: 127\n",
      "Episode: 513/5000, score: 127\n",
      "Episode: 514/5000, score: 106\n",
      "Episode: 515/5000, score: 123\n",
      "Episode: 516/5000, score: 113\n",
      "Episode: 517/5000, score: 141\n",
      "Episode: 518/5000, score: 110\n",
      "Episode: 519/5000, score: 127\n",
      "Episode: 520/5000, score: 152\n",
      "Episode: 521/5000, score: 127\n",
      "Episode: 522/5000, score: 153\n",
      "Episode: 523/5000, score: 172\n",
      "Episode: 524/5000, score: 131\n",
      "Episode: 525/5000, score: 103\n",
      "Episode: 526/5000, score: 137\n",
      "Episode: 527/5000, score: 161\n",
      "Episode: 528/5000, score: 128\n",
      "Episode: 529/5000, score: 112\n",
      "Episode: 530/5000, score: 150\n",
      "Episode: 531/5000, score: 148\n",
      "Episode: 532/5000, score: 138\n",
      "Episode: 533/5000, score: 154\n",
      "Episode: 534/5000, score: 127\n",
      "Episode: 535/5000, score: 115\n",
      "Episode: 536/5000, score: 144\n",
      "Episode: 537/5000, score: 168\n",
      "Episode: 538/5000, score: 158\n",
      "Episode: 539/5000, score: 140\n",
      "Episode: 540/5000, score: 115\n",
      "Episode: 541/5000, score: 126\n",
      "Episode: 542/5000, score: 146\n",
      "Episode: 543/5000, score: 136\n",
      "Episode: 544/5000, score: 150\n",
      "Episode: 545/5000, score: 202\n",
      "Episode: 546/5000, score: 125\n",
      "Episode: 547/5000, score: 117\n",
      "Episode: 548/5000, score: 223\n",
      "Episode: 549/5000, score: 170\n",
      "Episode: 550/5000, score: 222\n",
      "Episode: 551/5000, score: 196\n",
      "Episode: 552/5000, score: 182\n",
      "Episode: 553/5000, score: 223\n",
      "Episode: 554/5000, score: 222\n",
      "Episode: 555/5000, score: 287\n",
      "Episode: 556/5000, score: 159\n",
      "Episode: 557/5000, score: 137\n",
      "Episode: 558/5000, score: 126\n",
      "Episode: 559/5000, score: 244\n",
      "Episode: 560/5000, score: 152\n",
      "Episode: 561/5000, score: 104\n",
      "Episode: 562/5000, score: 112\n",
      "Episode: 563/5000, score: 135\n",
      "Episode: 564/5000, score: 117\n",
      "Episode: 565/5000, score: 114\n",
      "Episode: 566/5000, score: 147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 567/5000, score: 157\n",
      "Episode: 568/5000, score: 194\n",
      "Episode: 569/5000, score: 147\n",
      "Episode: 570/5000, score: 209\n",
      "Episode: 571/5000, score: 146\n",
      "Episode: 572/5000, score: 144\n",
      "Episode: 573/5000, score: 144\n",
      "Episode: 574/5000, score: 139\n",
      "Episode: 575/5000, score: 225\n",
      "Episode: 576/5000, score: 136\n",
      "Episode: 577/5000, score: 132\n",
      "Episode: 578/5000, score: 146\n",
      "Episode: 579/5000, score: 156\n",
      "Episode: 580/5000, score: 307\n",
      "Episode: 581/5000, score: 124\n",
      "Episode: 582/5000, score: 115\n",
      "Episode: 583/5000, score: 140\n",
      "Episode: 584/5000, score: 129\n",
      "Episode: 585/5000, score: 130\n",
      "Episode: 586/5000, score: 124\n",
      "Episode: 587/5000, score: 128\n",
      "Episode: 588/5000, score: 151\n",
      "Episode: 589/5000, score: 180\n",
      "Episode: 590/5000, score: 131\n",
      "Episode: 591/5000, score: 142\n",
      "Episode: 592/5000, score: 129\n",
      "Episode: 593/5000, score: 292\n",
      "Episode: 594/5000, score: 178\n",
      "Episode: 595/5000, score: 125\n",
      "Episode: 596/5000, score: 190\n",
      "Episode: 597/5000, score: 111\n",
      "Episode: 598/5000, score: 119\n",
      "Episode: 599/5000, score: 119\n",
      "Episode: 600/5000, score: 131\n",
      "Episode: 601/5000, score: 120\n",
      "Episode: 602/5000, score: 111\n",
      "Episode: 603/5000, score: 113\n",
      "Episode: 604/5000, score: 105\n",
      "Episode: 605/5000, score: 93\n",
      "Episode: 606/5000, score: 99\n",
      "Episode: 607/5000, score: 125\n",
      "Episode: 608/5000, score: 142\n",
      "Episode: 609/5000, score: 445\n",
      "Episode: 610/5000, score: 116\n",
      "Episode: 611/5000, score: 152\n",
      "Episode: 612/5000, score: 125\n",
      "Episode: 613/5000, score: 117\n",
      "Episode: 614/5000, score: 150\n",
      "Episode: 615/5000, score: 198\n",
      "Episode: 616/5000, score: 149\n",
      "Episode: 617/5000, score: 168\n",
      "Episode: 618/5000, score: 126\n",
      "Episode: 619/5000, score: 196\n",
      "Episode: 620/5000, score: 347\n",
      "Episode: 621/5000, score: 182\n",
      "Episode: 622/5000, score: 314\n",
      "Episode: 623/5000, score: 124\n",
      "Episode: 624/5000, score: 188\n",
      "Episode: 625/5000, score: 118\n",
      "Episode: 626/5000, score: 138\n",
      "Episode: 627/5000, score: 143\n",
      "Episode: 628/5000, score: 282\n",
      "Episode: 629/5000, score: 233\n",
      "Episode: 630/5000, score: 120\n",
      "Episode: 631/5000, score: 134\n",
      "Episode: 632/5000, score: 189\n",
      "Episode: 633/5000, score: 128\n",
      "Episode: 634/5000, score: 117\n",
      "Episode: 635/5000, score: 116\n",
      "Episode: 636/5000, score: 114\n",
      "Episode: 637/5000, score: 113\n",
      "Episode: 638/5000, score: 131\n",
      "Episode: 639/5000, score: 166\n",
      "Episode: 640/5000, score: 152\n",
      "Episode: 641/5000, score: 138\n",
      "Episode: 642/5000, score: 164\n",
      "Episode: 643/5000, score: 147\n",
      "Episode: 644/5000, score: 155\n",
      "Episode: 645/5000, score: 237\n",
      "Episode: 646/5000, score: 499\n",
      "Episode: 647/5000, score: 117\n",
      "Episode: 648/5000, score: 220\n",
      "Episode: 649/5000, score: 130\n",
      "Episode: 650/5000, score: 132\n",
      "Episode: 651/5000, score: 130\n",
      "Episode: 652/5000, score: 149\n",
      "Episode: 653/5000, score: 193\n",
      "Episode: 654/5000, score: 142\n",
      "Episode: 655/5000, score: 132\n",
      "Episode: 656/5000, score: 164\n",
      "Episode: 657/5000, score: 168\n",
      "Episode: 658/5000, score: 141\n",
      "Episode: 659/5000, score: 117\n",
      "Episode: 660/5000, score: 124\n",
      "Episode: 661/5000, score: 119\n",
      "Episode: 662/5000, score: 117\n",
      "Episode: 663/5000, score: 137\n",
      "Episode: 664/5000, score: 126\n",
      "Episode: 665/5000, score: 105\n",
      "Episode: 666/5000, score: 106\n",
      "Episode: 667/5000, score: 128\n",
      "Episode: 668/5000, score: 177\n",
      "Episode: 669/5000, score: 172\n",
      "Episode: 670/5000, score: 131\n",
      "Episode: 671/5000, score: 129\n",
      "Episode: 672/5000, score: 129\n",
      "Episode: 673/5000, score: 121\n",
      "Episode: 674/5000, score: 133\n",
      "Episode: 675/5000, score: 194\n",
      "Episode: 676/5000, score: 122\n",
      "Episode: 677/5000, score: 115\n",
      "Episode: 678/5000, score: 108\n",
      "Episode: 679/5000, score: 114\n",
      "Episode: 680/5000, score: 121\n",
      "Episode: 681/5000, score: 112\n",
      "Episode: 682/5000, score: 139\n",
      "Episode: 683/5000, score: 118\n",
      "Episode: 684/5000, score: 101\n",
      "Episode: 685/5000, score: 94\n",
      "Episode: 686/5000, score: 91\n",
      "Episode: 687/5000, score: 31\n",
      "Episode: 688/5000, score: 45\n",
      "Episode: 689/5000, score: 85\n",
      "Episode: 690/5000, score: 96\n",
      "Episode: 691/5000, score: 87\n",
      "Episode: 692/5000, score: 104\n",
      "Episode: 693/5000, score: 67\n",
      "Episode: 694/5000, score: 82\n",
      "Episode: 695/5000, score: 168\n",
      "Episode: 696/5000, score: 133\n",
      "Episode: 697/5000, score: 136\n",
      "Episode: 698/5000, score: 120\n",
      "Episode: 699/5000, score: 125\n",
      "Episode: 700/5000, score: 499\n",
      "Episode: 701/5000, score: 140\n",
      "Episode: 702/5000, score: 121\n",
      "Episode: 703/5000, score: 180\n",
      "Episode: 704/5000, score: 164\n",
      "Episode: 705/5000, score: 155\n",
      "Episode: 706/5000, score: 115\n",
      "Episode: 707/5000, score: 153\n",
      "Episode: 708/5000, score: 236\n",
      "Episode: 709/5000, score: 221\n",
      "Episode: 710/5000, score: 384\n",
      "Episode: 711/5000, score: 132\n",
      "Episode: 712/5000, score: 145\n",
      "Episode: 713/5000, score: 151\n",
      "Episode: 714/5000, score: 112\n",
      "Episode: 715/5000, score: 164\n",
      "Episode: 716/5000, score: 201\n",
      "Episode: 717/5000, score: 293\n",
      "Episode: 718/5000, score: 145\n",
      "Episode: 719/5000, score: 306\n",
      "Episode: 720/5000, score: 385\n",
      "Episode: 721/5000, score: 492\n",
      "Episode: 722/5000, score: 436\n",
      "Episode: 723/5000, score: 499\n",
      "Episode: 724/5000, score: 499\n",
      "Episode: 725/5000, score: 365\n",
      "Episode: 726/5000, score: 464\n",
      "Episode: 727/5000, score: 86\n",
      "Episode: 728/5000, score: 307\n",
      "Episode: 729/5000, score: 127\n",
      "Episode: 730/5000, score: 154\n",
      "Episode: 731/5000, score: 127\n",
      "Episode: 732/5000, score: 172\n",
      "Episode: 733/5000, score: 143\n",
      "Episode: 734/5000, score: 135\n",
      "Episode: 735/5000, score: 150\n",
      "Episode: 736/5000, score: 145\n",
      "Episode: 737/5000, score: 240\n",
      "Episode: 738/5000, score: 177\n",
      "Episode: 739/5000, score: 232\n",
      "Episode: 740/5000, score: 182\n",
      "Episode: 741/5000, score: 178\n",
      "Episode: 742/5000, score: 153\n",
      "Episode: 743/5000, score: 129\n",
      "Episode: 744/5000, score: 392\n",
      "Episode: 745/5000, score: 165\n",
      "Episode: 746/5000, score: 132\n",
      "Episode: 747/5000, score: 159\n",
      "Episode: 748/5000, score: 135\n",
      "Episode: 749/5000, score: 165\n",
      "Episode: 750/5000, score: 128\n",
      "Episode: 751/5000, score: 256\n",
      "Episode: 752/5000, score: 442\n",
      "Episode: 753/5000, score: 316\n",
      "Episode: 754/5000, score: 182\n",
      "Episode: 755/5000, score: 169\n",
      "Episode: 756/5000, score: 195\n",
      "Episode: 757/5000, score: 152\n",
      "Episode: 758/5000, score: 141\n",
      "Episode: 759/5000, score: 135\n",
      "Episode: 760/5000, score: 125\n",
      "Episode: 761/5000, score: 137\n",
      "Episode: 762/5000, score: 115\n",
      "Episode: 763/5000, score: 156\n",
      "Episode: 764/5000, score: 136\n",
      "Episode: 765/5000, score: 499\n",
      "Episode: 766/5000, score: 499\n",
      "Episode: 767/5000, score: 144\n",
      "Episode: 768/5000, score: 179\n",
      "Episode: 769/5000, score: 136\n",
      "Episode: 770/5000, score: 128\n",
      "Episode: 771/5000, score: 165\n",
      "Episode: 772/5000, score: 170\n",
      "Episode: 773/5000, score: 155\n",
      "Episode: 774/5000, score: 119\n",
      "Episode: 775/5000, score: 123\n",
      "Episode: 776/5000, score: 134\n",
      "Episode: 777/5000, score: 129\n",
      "Episode: 778/5000, score: 166\n",
      "Episode: 779/5000, score: 169\n",
      "Episode: 780/5000, score: 141\n",
      "Episode: 781/5000, score: 121\n",
      "Episode: 782/5000, score: 113\n",
      "Episode: 783/5000, score: 156\n",
      "Episode: 784/5000, score: 120\n",
      "Episode: 785/5000, score: 163\n",
      "Episode: 786/5000, score: 113\n",
      "Episode: 787/5000, score: 126\n",
      "Episode: 788/5000, score: 125\n",
      "Episode: 789/5000, score: 129\n",
      "Episode: 790/5000, score: 146\n",
      "Episode: 791/5000, score: 140\n",
      "Episode: 792/5000, score: 149\n",
      "Episode: 793/5000, score: 154\n",
      "Episode: 794/5000, score: 152\n",
      "Episode: 795/5000, score: 192\n",
      "Episode: 796/5000, score: 163\n",
      "Episode: 797/5000, score: 220\n",
      "Episode: 798/5000, score: 242\n",
      "Episode: 799/5000, score: 236\n",
      "Episode: 800/5000, score: 346\n",
      "Episode: 801/5000, score: 151\n",
      "Episode: 802/5000, score: 157\n",
      "Episode: 803/5000, score: 233\n",
      "Episode: 804/5000, score: 311\n",
      "Episode: 805/5000, score: 131\n",
      "Episode: 806/5000, score: 138\n",
      "Episode: 807/5000, score: 142\n",
      "Episode: 808/5000, score: 448\n",
      "Episode: 809/5000, score: 250\n",
      "Episode: 810/5000, score: 122\n",
      "Episode: 811/5000, score: 127\n",
      "Episode: 812/5000, score: 228\n",
      "Episode: 813/5000, score: 158\n",
      "Episode: 814/5000, score: 160\n",
      "Episode: 815/5000, score: 186\n",
      "Episode: 816/5000, score: 470\n",
      "Episode: 817/5000, score: 426\n",
      "Episode: 818/5000, score: 265\n",
      "Episode: 819/5000, score: 149\n",
      "Episode: 820/5000, score: 238\n",
      "Episode: 821/5000, score: 185\n",
      "Episode: 822/5000, score: 233\n",
      "Episode: 823/5000, score: 262\n",
      "Episode: 824/5000, score: 136\n",
      "Episode: 825/5000, score: 182\n",
      "Episode: 826/5000, score: 159\n",
      "Episode: 827/5000, score: 131\n",
      "Episode: 828/5000, score: 178\n",
      "Episode: 829/5000, score: 134\n",
      "Episode: 830/5000, score: 204\n",
      "Episode: 831/5000, score: 223\n",
      "Episode: 832/5000, score: 499\n",
      "Episode: 833/5000, score: 439\n",
      "Episode: 834/5000, score: 200\n",
      "Episode: 835/5000, score: 360\n",
      "Episode: 836/5000, score: 499\n",
      "Episode: 837/5000, score: 193\n",
      "Episode: 838/5000, score: 167\n",
      "Episode: 839/5000, score: 213\n",
      "Episode: 840/5000, score: 367\n",
      "Episode: 841/5000, score: 140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 842/5000, score: 173\n",
      "Episode: 843/5000, score: 146\n",
      "Episode: 844/5000, score: 220\n",
      "Episode: 845/5000, score: 144\n",
      "Episode: 846/5000, score: 168\n",
      "Episode: 847/5000, score: 135\n",
      "Episode: 848/5000, score: 151\n",
      "Episode: 849/5000, score: 145\n",
      "Episode: 850/5000, score: 132\n",
      "Episode: 851/5000, score: 119\n",
      "Episode: 852/5000, score: 146\n",
      "Episode: 853/5000, score: 140\n",
      "Episode: 854/5000, score: 125\n",
      "Episode: 855/5000, score: 130\n",
      "Episode: 856/5000, score: 285\n",
      "Episode: 857/5000, score: 277\n",
      "Episode: 858/5000, score: 499\n",
      "Episode: 859/5000, score: 236\n",
      "Episode: 860/5000, score: 251\n",
      "Episode: 861/5000, score: 222\n",
      "Episode: 862/5000, score: 232\n",
      "Episode: 863/5000, score: 190\n",
      "Episode: 864/5000, score: 499\n",
      "Episode: 865/5000, score: 499\n",
      "Episode: 866/5000, score: 183\n",
      "Episode: 867/5000, score: 160\n",
      "Episode: 868/5000, score: 230\n",
      "Episode: 869/5000, score: 258\n",
      "Episode: 870/5000, score: 274\n",
      "Episode: 871/5000, score: 208\n",
      "Episode: 872/5000, score: 148\n",
      "Episode: 873/5000, score: 185\n",
      "Episode: 874/5000, score: 265\n",
      "Episode: 875/5000, score: 231\n",
      "Episode: 876/5000, score: 204\n",
      "Episode: 877/5000, score: 349\n",
      "Episode: 878/5000, score: 343\n",
      "Episode: 879/5000, score: 202\n",
      "Episode: 880/5000, score: 467\n",
      "Episode: 881/5000, score: 235\n",
      "Episode: 882/5000, score: 173\n",
      "Episode: 883/5000, score: 141\n",
      "Episode: 884/5000, score: 138\n",
      "Episode: 885/5000, score: 107\n",
      "Episode: 886/5000, score: 312\n",
      "Episode: 887/5000, score: 499\n",
      "Episode: 888/5000, score: 311\n",
      "Episode: 889/5000, score: 488\n",
      "Episode: 890/5000, score: 234\n",
      "Episode: 891/5000, score: 391\n",
      "Episode: 892/5000, score: 314\n",
      "Episode: 893/5000, score: 211\n",
      "Episode: 894/5000, score: 209\n",
      "Episode: 895/5000, score: 220\n",
      "Episode: 896/5000, score: 234\n",
      "Episode: 897/5000, score: 415\n",
      "Episode: 898/5000, score: 499\n",
      "Episode: 899/5000, score: 395\n",
      "Episode: 900/5000, score: 212\n",
      "Episode: 901/5000, score: 273\n",
      "Episode: 902/5000, score: 134\n",
      "Episode: 903/5000, score: 473\n",
      "Episode: 904/5000, score: 329\n",
      "Episode: 905/5000, score: 499\n",
      "Episode: 906/5000, score: 385\n",
      "Episode: 907/5000, score: 243\n",
      "Episode: 908/5000, score: 499\n",
      "Episode: 909/5000, score: 201\n",
      "Episode: 910/5000, score: 337\n",
      "Episode: 911/5000, score: 409\n",
      "Episode: 912/5000, score: 268\n",
      "Episode: 913/5000, score: 343\n",
      "Episode: 914/5000, score: 123\n",
      "Episode: 915/5000, score: 207\n",
      "Episode: 916/5000, score: 198\n",
      "Episode: 917/5000, score: 129\n",
      "Episode: 918/5000, score: 233\n",
      "Episode: 919/5000, score: 317\n",
      "Episode: 920/5000, score: 272\n",
      "Episode: 921/5000, score: 236\n",
      "Episode: 922/5000, score: 169\n",
      "Episode: 923/5000, score: 279\n",
      "Episode: 924/5000, score: 170\n",
      "Episode: 925/5000, score: 163\n",
      "Episode: 926/5000, score: 198\n",
      "Episode: 927/5000, score: 488\n",
      "Episode: 928/5000, score: 198\n",
      "Episode: 929/5000, score: 253\n",
      "Episode: 930/5000, score: 132\n",
      "Episode: 931/5000, score: 221\n",
      "Episode: 932/5000, score: 195\n",
      "Episode: 933/5000, score: 184\n",
      "Episode: 934/5000, score: 499\n",
      "Episode: 935/5000, score: 227\n",
      "Episode: 936/5000, score: 152\n",
      "Episode: 937/5000, score: 145\n",
      "Episode: 938/5000, score: 435\n",
      "Episode: 939/5000, score: 349\n",
      "Episode: 940/5000, score: 168\n",
      "Episode: 941/5000, score: 136\n",
      "Episode: 942/5000, score: 236\n",
      "Episode: 943/5000, score: 259\n",
      "Episode: 944/5000, score: 158\n",
      "Episode: 945/5000, score: 300\n",
      "Episode: 946/5000, score: 320\n",
      "Episode: 947/5000, score: 270\n",
      "Episode: 948/5000, score: 214\n",
      "Episode: 949/5000, score: 276\n",
      "Episode: 950/5000, score: 197\n",
      "Episode: 951/5000, score: 183\n",
      "Episode: 952/5000, score: 499\n",
      "Episode: 953/5000, score: 497\n",
      "Episode: 954/5000, score: 359\n",
      "Episode: 955/5000, score: 384\n",
      "Episode: 956/5000, score: 226\n",
      "Episode: 957/5000, score: 195\n",
      "Episode: 958/5000, score: 186\n",
      "Episode: 959/5000, score: 148\n",
      "Episode: 960/5000, score: 136\n",
      "Episode: 961/5000, score: 142\n",
      "Episode: 962/5000, score: 142\n",
      "Episode: 963/5000, score: 134\n",
      "Episode: 964/5000, score: 149\n",
      "Episode: 965/5000, score: 112\n",
      "Episode: 966/5000, score: 172\n",
      "Episode: 967/5000, score: 242\n",
      "Episode: 968/5000, score: 193\n",
      "Episode: 969/5000, score: 435\n",
      "Episode: 970/5000, score: 136\n",
      "Episode: 971/5000, score: 161\n",
      "Episode: 972/5000, score: 126\n",
      "Episode: 973/5000, score: 174\n",
      "Episode: 974/5000, score: 200\n",
      "Episode: 975/5000, score: 144\n",
      "Episode: 976/5000, score: 178\n",
      "Episode: 977/5000, score: 129\n",
      "Episode: 978/5000, score: 123\n",
      "Episode: 979/5000, score: 193\n",
      "Episode: 980/5000, score: 227\n",
      "Episode: 981/5000, score: 170\n",
      "Episode: 982/5000, score: 193\n",
      "Episode: 983/5000, score: 279\n",
      "Episode: 984/5000, score: 159\n",
      "Episode: 985/5000, score: 164\n",
      "Episode: 986/5000, score: 326\n",
      "Episode: 987/5000, score: 291\n",
      "Episode: 988/5000, score: 176\n",
      "Episode: 989/5000, score: 156\n",
      "Episode: 990/5000, score: 142\n",
      "Episode: 991/5000, score: 141\n",
      "Episode: 992/5000, score: 120\n",
      "Episode: 993/5000, score: 160\n",
      "Episode: 994/5000, score: 170\n",
      "Episode: 995/5000, score: 176\n",
      "Episode: 996/5000, score: 499\n",
      "Episode: 997/5000, score: 152\n",
      "Episode: 998/5000, score: 181\n",
      "Episode: 999/5000, score: 219\n",
      "Episode: 1000/5000, score: 289\n",
      "Episode: 1001/5000, score: 246\n",
      "Episode: 1002/5000, score: 132\n",
      "Episode: 1003/5000, score: 187\n",
      "Episode: 1004/5000, score: 128\n",
      "Episode: 1005/5000, score: 210\n",
      "Episode: 1006/5000, score: 312\n",
      "Episode: 1007/5000, score: 178\n",
      "Episode: 1008/5000, score: 183\n",
      "Episode: 1009/5000, score: 413\n",
      "Episode: 1010/5000, score: 499\n",
      "Episode: 1011/5000, score: 260\n",
      "Episode: 1012/5000, score: 193\n",
      "Episode: 1013/5000, score: 171\n",
      "Episode: 1014/5000, score: 140\n",
      "Episode: 1015/5000, score: 122\n",
      "Episode: 1016/5000, score: 141\n",
      "Episode: 1017/5000, score: 257\n",
      "Episode: 1018/5000, score: 141\n",
      "Episode: 1019/5000, score: 242\n",
      "Episode: 1020/5000, score: 146\n",
      "Episode: 1021/5000, score: 158\n",
      "Episode: 1022/5000, score: 266\n",
      "Episode: 1023/5000, score: 390\n",
      "Episode: 1024/5000, score: 89\n",
      "Episode: 1025/5000, score: 9\n",
      "Episode: 1026/5000, score: 145\n",
      "Episode: 1027/5000, score: 115\n",
      "Episode: 1028/5000, score: 20\n",
      "Episode: 1029/5000, score: 111\n",
      "Episode: 1030/5000, score: 108\n",
      "Episode: 1031/5000, score: 110\n",
      "Episode: 1032/5000, score: 13\n",
      "Episode: 1033/5000, score: 129\n",
      "Episode: 1034/5000, score: 109\n",
      "Episode: 1035/5000, score: 111\n",
      "Episode: 1036/5000, score: 14\n",
      "Episode: 1037/5000, score: 11\n",
      "Episode: 1038/5000, score: 11\n",
      "Episode: 1039/5000, score: 14\n",
      "Episode: 1040/5000, score: 18\n",
      "Episode: 1041/5000, score: 155\n",
      "Episode: 1042/5000, score: 345\n",
      "Episode: 1043/5000, score: 169\n",
      "Episode: 1044/5000, score: 201\n",
      "Episode: 1045/5000, score: 345\n",
      "Episode: 1046/5000, score: 391\n",
      "Episode: 1047/5000, score: 277\n",
      "Episode: 1048/5000, score: 240\n",
      "Episode: 1049/5000, score: 170\n",
      "Episode: 1050/5000, score: 200\n",
      "Episode: 1051/5000, score: 175\n",
      "Episode: 1052/5000, score: 154\n",
      "Episode: 1053/5000, score: 141\n",
      "Episode: 1054/5000, score: 142\n",
      "Episode: 1055/5000, score: 145\n",
      "Episode: 1056/5000, score: 214\n",
      "Episode: 1057/5000, score: 147\n",
      "Episode: 1058/5000, score: 187\n",
      "Episode: 1059/5000, score: 181\n",
      "Episode: 1060/5000, score: 452\n",
      "Episode: 1061/5000, score: 170\n",
      "Episode: 1062/5000, score: 178\n",
      "Episode: 1063/5000, score: 323\n",
      "Episode: 1064/5000, score: 293\n",
      "Episode: 1065/5000, score: 136\n",
      "Episode: 1066/5000, score: 324\n",
      "Episode: 1067/5000, score: 213\n",
      "Episode: 1068/5000, score: 150\n",
      "Episode: 1069/5000, score: 112\n",
      "Episode: 1070/5000, score: 116\n",
      "Episode: 1071/5000, score: 103\n",
      "Episode: 1072/5000, score: 271\n",
      "Episode: 1073/5000, score: 113\n",
      "Episode: 1074/5000, score: 167\n",
      "Episode: 1075/5000, score: 202\n",
      "Episode: 1076/5000, score: 228\n",
      "Episode: 1077/5000, score: 347\n",
      "Episode: 1078/5000, score: 300\n",
      "Episode: 1079/5000, score: 147\n",
      "Episode: 1080/5000, score: 139\n",
      "Episode: 1081/5000, score: 151\n",
      "Episode: 1082/5000, score: 147\n",
      "Episode: 1083/5000, score: 173\n",
      "Episode: 1084/5000, score: 166\n",
      "Episode: 1085/5000, score: 180\n",
      "Episode: 1086/5000, score: 135\n",
      "Episode: 1087/5000, score: 189\n",
      "Episode: 1088/5000, score: 201\n",
      "Episode: 1089/5000, score: 185\n",
      "Episode: 1090/5000, score: 206\n",
      "Episode: 1091/5000, score: 157\n",
      "Episode: 1092/5000, score: 438\n",
      "Episode: 1093/5000, score: 224\n",
      "Episode: 1094/5000, score: 291\n",
      "Episode: 1095/5000, score: 113\n",
      "Episode: 1096/5000, score: 350\n",
      "Episode: 1097/5000, score: 310\n",
      "Episode: 1098/5000, score: 292\n",
      "Episode: 1099/5000, score: 218\n",
      "Episode: 1100/5000, score: 344\n",
      "Episode: 1101/5000, score: 253\n",
      "Episode: 1102/5000, score: 192\n",
      "Episode: 1103/5000, score: 220\n",
      "Episode: 1104/5000, score: 132\n",
      "Episode: 1105/5000, score: 152\n",
      "Episode: 1106/5000, score: 270\n",
      "Episode: 1107/5000, score: 229\n",
      "Episode: 1108/5000, score: 159\n",
      "Episode: 1109/5000, score: 495\n",
      "Episode: 1110/5000, score: 215\n",
      "Episode: 1111/5000, score: 105\n",
      "Episode: 1112/5000, score: 327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1113/5000, score: 149\n",
      "Episode: 1114/5000, score: 149\n",
      "Episode: 1115/5000, score: 249\n",
      "Episode: 1116/5000, score: 277\n",
      "Episode: 1117/5000, score: 164\n",
      "Episode: 1118/5000, score: 206\n",
      "Episode: 1119/5000, score: 203\n",
      "Episode: 1120/5000, score: 164\n",
      "Episode: 1121/5000, score: 181\n",
      "Episode: 1122/5000, score: 455\n",
      "Episode: 1123/5000, score: 499\n",
      "Episode: 1124/5000, score: 265\n",
      "Episode: 1125/5000, score: 364\n",
      "Episode: 1126/5000, score: 149\n",
      "Episode: 1127/5000, score: 176\n",
      "Episode: 1128/5000, score: 267\n",
      "Episode: 1129/5000, score: 136\n",
      "Episode: 1130/5000, score: 186\n",
      "Episode: 1131/5000, score: 160\n",
      "Episode: 1132/5000, score: 131\n",
      "Episode: 1133/5000, score: 123\n",
      "Episode: 1134/5000, score: 133\n",
      "Episode: 1135/5000, score: 151\n",
      "Episode: 1136/5000, score: 145\n",
      "Episode: 1137/5000, score: 149\n",
      "Episode: 1138/5000, score: 146\n",
      "Episode: 1139/5000, score: 229\n",
      "Episode: 1140/5000, score: 194\n",
      "Episode: 1141/5000, score: 162\n",
      "Episode: 1142/5000, score: 173\n",
      "Episode: 1143/5000, score: 186\n",
      "Episode: 1144/5000, score: 128\n",
      "Episode: 1145/5000, score: 139\n",
      "Episode: 1146/5000, score: 125\n",
      "Episode: 1147/5000, score: 130\n",
      "Episode: 1148/5000, score: 157\n",
      "Episode: 1149/5000, score: 158\n",
      "Episode: 1150/5000, score: 143\n",
      "Episode: 1151/5000, score: 142\n",
      "Episode: 1152/5000, score: 149\n",
      "Episode: 1153/5000, score: 129\n",
      "Episode: 1154/5000, score: 147\n",
      "Episode: 1155/5000, score: 137\n",
      "Episode: 1156/5000, score: 169\n",
      "Episode: 1157/5000, score: 144\n",
      "Episode: 1158/5000, score: 137\n",
      "Episode: 1159/5000, score: 276\n",
      "Episode: 1160/5000, score: 154\n",
      "Episode: 1161/5000, score: 150\n",
      "Episode: 1162/5000, score: 198\n",
      "Episode: 1163/5000, score: 144\n",
      "Episode: 1164/5000, score: 174\n",
      "Episode: 1165/5000, score: 143\n",
      "Episode: 1166/5000, score: 142\n",
      "Episode: 1167/5000, score: 177\n",
      "Episode: 1168/5000, score: 172\n",
      "Episode: 1169/5000, score: 248\n",
      "Episode: 1170/5000, score: 124\n",
      "Episode: 1171/5000, score: 231\n",
      "Episode: 1172/5000, score: 467\n",
      "Episode: 1173/5000, score: 265\n",
      "Episode: 1174/5000, score: 150\n",
      "Episode: 1175/5000, score: 152\n",
      "Episode: 1176/5000, score: 152\n",
      "Episode: 1177/5000, score: 212\n",
      "Episode: 1178/5000, score: 302\n",
      "Episode: 1179/5000, score: 194\n",
      "Episode: 1180/5000, score: 357\n",
      "Episode: 1181/5000, score: 268\n",
      "Episode: 1182/5000, score: 284\n",
      "Episode: 1183/5000, score: 205\n",
      "Episode: 1184/5000, score: 138\n",
      "Episode: 1185/5000, score: 298\n",
      "Episode: 1186/5000, score: 141\n",
      "Episode: 1187/5000, score: 147\n",
      "Episode: 1188/5000, score: 136\n",
      "Episode: 1189/5000, score: 499\n",
      "Episode: 1190/5000, score: 426\n",
      "Episode: 1191/5000, score: 499\n",
      "Episode: 1192/5000, score: 178\n",
      "Episode: 1193/5000, score: 255\n",
      "Episode: 1194/5000, score: 130\n",
      "Episode: 1195/5000, score: 218\n",
      "Episode: 1196/5000, score: 155\n",
      "Episode: 1197/5000, score: 150\n",
      "Episode: 1198/5000, score: 277\n",
      "Episode: 1199/5000, score: 196\n",
      "Episode: 1200/5000, score: 145\n",
      "Episode: 1201/5000, score: 184\n",
      "Episode: 1202/5000, score: 122\n",
      "Episode: 1203/5000, score: 159\n",
      "Episode: 1204/5000, score: 196\n",
      "Episode: 1205/5000, score: 184\n",
      "Episode: 1206/5000, score: 176\n",
      "Episode: 1207/5000, score: 153\n",
      "Episode: 1208/5000, score: 212\n",
      "Episode: 1209/5000, score: 157\n",
      "Episode: 1210/5000, score: 183\n",
      "Episode: 1211/5000, score: 146\n",
      "Episode: 1212/5000, score: 176\n",
      "Episode: 1213/5000, score: 131\n",
      "Episode: 1214/5000, score: 199\n",
      "Episode: 1215/5000, score: 325\n",
      "Episode: 1216/5000, score: 283\n",
      "Episode: 1217/5000, score: 147\n",
      "Episode: 1218/5000, score: 301\n",
      "Episode: 1219/5000, score: 99\n",
      "Episode: 1220/5000, score: 241\n",
      "Episode: 1221/5000, score: 209\n",
      "Episode: 1222/5000, score: 272\n",
      "Episode: 1223/5000, score: 274\n",
      "Episode: 1224/5000, score: 178\n",
      "Episode: 1225/5000, score: 216\n",
      "Episode: 1226/5000, score: 386\n",
      "Episode: 1227/5000, score: 181\n",
      "Episode: 1228/5000, score: 127\n",
      "Episode: 1229/5000, score: 143\n",
      "Episode: 1230/5000, score: 171\n",
      "Episode: 1231/5000, score: 153\n",
      "Episode: 1232/5000, score: 122\n",
      "Episode: 1233/5000, score: 137\n",
      "Episode: 1234/5000, score: 143\n",
      "Episode: 1235/5000, score: 272\n",
      "Episode: 1236/5000, score: 133\n",
      "Episode: 1237/5000, score: 132\n",
      "Episode: 1238/5000, score: 127\n",
      "Episode: 1239/5000, score: 132\n",
      "Episode: 1240/5000, score: 156\n",
      "Episode: 1241/5000, score: 151\n",
      "Episode: 1242/5000, score: 131\n",
      "Episode: 1243/5000, score: 154\n",
      "Episode: 1244/5000, score: 148\n",
      "Episode: 1245/5000, score: 152\n",
      "Episode: 1246/5000, score: 125\n",
      "Episode: 1247/5000, score: 242\n",
      "Episode: 1248/5000, score: 161\n",
      "Episode: 1249/5000, score: 158\n",
      "Episode: 1250/5000, score: 158\n",
      "Episode: 1251/5000, score: 198\n",
      "Episode: 1252/5000, score: 129\n",
      "Episode: 1253/5000, score: 147\n",
      "Episode: 1254/5000, score: 499\n",
      "Episode: 1255/5000, score: 149\n",
      "Episode: 1256/5000, score: 144\n",
      "Episode: 1257/5000, score: 144\n",
      "Episode: 1258/5000, score: 273\n",
      "Episode: 1259/5000, score: 129\n",
      "Episode: 1260/5000, score: 123\n",
      "Episode: 1261/5000, score: 140\n",
      "Episode: 1262/5000, score: 137\n",
      "Episode: 1263/5000, score: 156\n",
      "Episode: 1264/5000, score: 302\n",
      "Episode: 1265/5000, score: 132\n",
      "Episode: 1266/5000, score: 176\n",
      "Episode: 1267/5000, score: 127\n",
      "Episode: 1268/5000, score: 166\n",
      "Episode: 1269/5000, score: 278\n",
      "Episode: 1270/5000, score: 284\n",
      "Episode: 1271/5000, score: 340\n",
      "Episode: 1272/5000, score: 245\n",
      "Episode: 1273/5000, score: 173\n",
      "Episode: 1274/5000, score: 149\n",
      "Episode: 1275/5000, score: 155\n",
      "Episode: 1276/5000, score: 140\n",
      "Episode: 1277/5000, score: 151\n",
      "Episode: 1278/5000, score: 156\n",
      "Episode: 1279/5000, score: 499\n",
      "Episode: 1280/5000, score: 233\n",
      "Episode: 1281/5000, score: 150\n",
      "Episode: 1282/5000, score: 176\n",
      "Episode: 1283/5000, score: 189\n",
      "Episode: 1284/5000, score: 168\n",
      "Episode: 1285/5000, score: 129\n",
      "Episode: 1286/5000, score: 167\n",
      "Episode: 1287/5000, score: 320\n",
      "Episode: 1288/5000, score: 160\n",
      "Episode: 1289/5000, score: 140\n",
      "Episode: 1290/5000, score: 126\n",
      "Episode: 1291/5000, score: 171\n",
      "Episode: 1292/5000, score: 149\n",
      "Episode: 1293/5000, score: 152\n",
      "Episode: 1294/5000, score: 173\n",
      "Episode: 1295/5000, score: 135\n",
      "Episode: 1296/5000, score: 153\n",
      "Episode: 1297/5000, score: 133\n",
      "Episode: 1298/5000, score: 138\n",
      "Episode: 1299/5000, score: 138\n",
      "Episode: 1300/5000, score: 138\n",
      "Episode: 1301/5000, score: 181\n",
      "Episode: 1302/5000, score: 247\n",
      "Episode: 1303/5000, score: 424\n",
      "Episode: 1304/5000, score: 143\n",
      "Episode: 1305/5000, score: 126\n",
      "Episode: 1306/5000, score: 137\n",
      "Episode: 1307/5000, score: 126\n",
      "Episode: 1308/5000, score: 117\n",
      "Episode: 1309/5000, score: 128\n",
      "Episode: 1310/5000, score: 123\n",
      "Episode: 1311/5000, score: 138\n",
      "Episode: 1312/5000, score: 133\n",
      "Episode: 1313/5000, score: 127\n",
      "Episode: 1314/5000, score: 134\n",
      "Episode: 1315/5000, score: 135\n",
      "Episode: 1316/5000, score: 143\n",
      "Episode: 1317/5000, score: 171\n",
      "Episode: 1318/5000, score: 120\n",
      "Episode: 1319/5000, score: 137\n",
      "Episode: 1320/5000, score: 106\n",
      "Episode: 1321/5000, score: 130\n",
      "Episode: 1322/5000, score: 307\n",
      "Episode: 1323/5000, score: 216\n",
      "Episode: 1324/5000, score: 186\n",
      "Episode: 1325/5000, score: 196\n",
      "Episode: 1326/5000, score: 199\n",
      "Episode: 1327/5000, score: 240\n",
      "Episode: 1328/5000, score: 278\n",
      "Episode: 1329/5000, score: 267\n",
      "Episode: 1330/5000, score: 362\n",
      "Episode: 1331/5000, score: 499\n",
      "Episode: 1332/5000, score: 167\n",
      "Episode: 1333/5000, score: 415\n",
      "Episode: 1334/5000, score: 218\n",
      "Episode: 1335/5000, score: 226\n",
      "Episode: 1336/5000, score: 162\n",
      "Episode: 1337/5000, score: 234\n",
      "Episode: 1338/5000, score: 189\n",
      "Episode: 1339/5000, score: 324\n",
      "Episode: 1340/5000, score: 347\n",
      "Episode: 1341/5000, score: 157\n",
      "Episode: 1342/5000, score: 352\n",
      "Episode: 1343/5000, score: 426\n",
      "Episode: 1344/5000, score: 499\n",
      "Episode: 1345/5000, score: 424\n",
      "Episode: 1346/5000, score: 354\n",
      "Episode: 1347/5000, score: 171\n",
      "Episode: 1348/5000, score: 163\n",
      "Episode: 1349/5000, score: 119\n",
      "Episode: 1350/5000, score: 157\n",
      "Episode: 1351/5000, score: 168\n",
      "Episode: 1352/5000, score: 178\n",
      "Episode: 1353/5000, score: 139\n",
      "Episode: 1354/5000, score: 154\n",
      "Episode: 1355/5000, score: 184\n",
      "Episode: 1356/5000, score: 138\n",
      "Episode: 1357/5000, score: 127\n",
      "Episode: 1358/5000, score: 143\n",
      "Episode: 1359/5000, score: 138\n",
      "Episode: 1360/5000, score: 175\n",
      "Episode: 1361/5000, score: 134\n",
      "Episode: 1362/5000, score: 175\n",
      "Episode: 1363/5000, score: 146\n",
      "Episode: 1364/5000, score: 123\n",
      "Episode: 1365/5000, score: 173\n",
      "Episode: 1366/5000, score: 186\n",
      "Episode: 1367/5000, score: 135\n",
      "Episode: 1368/5000, score: 159\n",
      "Episode: 1369/5000, score: 181\n",
      "Episode: 1370/5000, score: 161\n",
      "Episode: 1371/5000, score: 139\n",
      "Episode: 1372/5000, score: 175\n",
      "Episode: 1373/5000, score: 157\n",
      "Episode: 1374/5000, score: 126\n",
      "Episode: 1375/5000, score: 159\n",
      "Episode: 1376/5000, score: 126\n",
      "Episode: 1377/5000, score: 132\n",
      "Episode: 1378/5000, score: 131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1379/5000, score: 242\n",
      "Episode: 1380/5000, score: 135\n",
      "Episode: 1381/5000, score: 167\n",
      "Episode: 1382/5000, score: 136\n",
      "Episode: 1383/5000, score: 166\n",
      "Episode: 1384/5000, score: 139\n",
      "Episode: 1385/5000, score: 150\n",
      "Episode: 1386/5000, score: 150\n",
      "Episode: 1387/5000, score: 433\n",
      "Episode: 1388/5000, score: 278\n",
      "Episode: 1389/5000, score: 401\n",
      "Episode: 1390/5000, score: 174\n",
      "Episode: 1391/5000, score: 174\n",
      "Episode: 1392/5000, score: 133\n",
      "Episode: 1393/5000, score: 148\n",
      "Episode: 1394/5000, score: 144\n",
      "Episode: 1395/5000, score: 204\n",
      "Episode: 1396/5000, score: 127\n",
      "Episode: 1397/5000, score: 213\n",
      "Episode: 1398/5000, score: 214\n",
      "Episode: 1399/5000, score: 430\n",
      "Episode: 1400/5000, score: 299\n",
      "Episode: 1401/5000, score: 110\n",
      "Episode: 1402/5000, score: 151\n",
      "Episode: 1403/5000, score: 125\n",
      "Episode: 1404/5000, score: 143\n",
      "Episode: 1405/5000, score: 118\n",
      "Episode: 1406/5000, score: 158\n",
      "Episode: 1407/5000, score: 131\n",
      "Episode: 1408/5000, score: 270\n",
      "Episode: 1409/5000, score: 177\n",
      "Episode: 1410/5000, score: 124\n",
      "Episode: 1411/5000, score: 159\n",
      "Episode: 1412/5000, score: 197\n",
      "Episode: 1413/5000, score: 174\n",
      "Episode: 1414/5000, score: 143\n",
      "Episode: 1415/5000, score: 146\n",
      "Episode: 1416/5000, score: 495\n",
      "Episode: 1417/5000, score: 230\n",
      "Episode: 1418/5000, score: 352\n",
      "Episode: 1419/5000, score: 144\n",
      "Episode: 1420/5000, score: 322\n",
      "Episode: 1421/5000, score: 164\n",
      "Episode: 1422/5000, score: 346\n",
      "Episode: 1423/5000, score: 111\n",
      "Episode: 1424/5000, score: 499\n",
      "Episode: 1425/5000, score: 243\n",
      "Episode: 1426/5000, score: 413\n",
      "Episode: 1427/5000, score: 152\n",
      "Episode: 1428/5000, score: 362\n",
      "Episode: 1429/5000, score: 141\n",
      "Episode: 1430/5000, score: 143\n",
      "Episode: 1431/5000, score: 135\n",
      "Episode: 1432/5000, score: 158\n",
      "Episode: 1433/5000, score: 137\n",
      "Episode: 1434/5000, score: 119\n",
      "Episode: 1435/5000, score: 131\n",
      "Episode: 1436/5000, score: 137\n",
      "Episode: 1437/5000, score: 122\n",
      "Episode: 1438/5000, score: 115\n",
      "Episode: 1439/5000, score: 117\n",
      "Episode: 1440/5000, score: 130\n",
      "Episode: 1441/5000, score: 158\n",
      "Episode: 1442/5000, score: 120\n",
      "Episode: 1443/5000, score: 116\n",
      "Episode: 1444/5000, score: 129\n",
      "Episode: 1445/5000, score: 124\n",
      "Episode: 1446/5000, score: 148\n",
      "Episode: 1447/5000, score: 360\n",
      "Episode: 1448/5000, score: 164\n",
      "Episode: 1449/5000, score: 139\n",
      "Episode: 1450/5000, score: 132\n",
      "Episode: 1451/5000, score: 146\n",
      "Episode: 1452/5000, score: 137\n",
      "Episode: 1453/5000, score: 126\n",
      "Episode: 1454/5000, score: 198\n",
      "Episode: 1455/5000, score: 281\n",
      "Episode: 1456/5000, score: 499\n",
      "Episode: 1457/5000, score: 288\n",
      "Episode: 1458/5000, score: 499\n",
      "Episode: 1459/5000, score: 346\n",
      "Episode: 1460/5000, score: 292\n",
      "Episode: 1461/5000, score: 346\n",
      "Episode: 1462/5000, score: 130\n",
      "Episode: 1463/5000, score: 138\n",
      "Episode: 1464/5000, score: 173\n",
      "Episode: 1465/5000, score: 193\n",
      "Episode: 1466/5000, score: 182\n",
      "Episode: 1467/5000, score: 406\n",
      "Episode: 1468/5000, score: 196\n",
      "Episode: 1469/5000, score: 200\n",
      "Episode: 1470/5000, score: 368\n",
      "Episode: 1471/5000, score: 153\n",
      "Episode: 1472/5000, score: 137\n",
      "Episode: 1473/5000, score: 307\n",
      "Episode: 1474/5000, score: 499\n",
      "Episode: 1475/5000, score: 265\n",
      "Episode: 1476/5000, score: 218\n",
      "Episode: 1477/5000, score: 137\n",
      "Episode: 1478/5000, score: 137\n",
      "Episode: 1479/5000, score: 118\n",
      "Episode: 1480/5000, score: 487\n",
      "Episode: 1481/5000, score: 127\n",
      "Episode: 1482/5000, score: 292\n",
      "Episode: 1483/5000, score: 155\n",
      "Episode: 1484/5000, score: 302\n",
      "Episode: 1485/5000, score: 301\n",
      "Episode: 1486/5000, score: 157\n",
      "Episode: 1487/5000, score: 177\n",
      "Episode: 1488/5000, score: 163\n",
      "Episode: 1489/5000, score: 159\n",
      "Episode: 1490/5000, score: 147\n",
      "Episode: 1491/5000, score: 129\n",
      "Episode: 1492/5000, score: 146\n",
      "Episode: 1493/5000, score: 194\n",
      "Episode: 1494/5000, score: 142\n",
      "Episode: 1495/5000, score: 197\n",
      "Episode: 1496/5000, score: 156\n",
      "Episode: 1497/5000, score: 173\n",
      "Episode: 1498/5000, score: 221\n",
      "Episode: 1499/5000, score: 216\n",
      "Episode: 1500/5000, score: 205\n",
      "Episode: 1501/5000, score: 433\n",
      "Episode: 1502/5000, score: 230\n",
      "Episode: 1503/5000, score: 184\n",
      "Episode: 1504/5000, score: 269\n",
      "Episode: 1505/5000, score: 453\n",
      "Episode: 1506/5000, score: 158\n",
      "Episode: 1507/5000, score: 187\n",
      "Episode: 1508/5000, score: 350\n",
      "Episode: 1509/5000, score: 153\n",
      "Episode: 1510/5000, score: 188\n",
      "Episode: 1511/5000, score: 128\n",
      "Episode: 1512/5000, score: 147\n",
      "Episode: 1513/5000, score: 265\n",
      "Episode: 1514/5000, score: 143\n",
      "Episode: 1515/5000, score: 395\n",
      "Episode: 1516/5000, score: 198\n",
      "Episode: 1517/5000, score: 130\n",
      "Episode: 1518/5000, score: 324\n",
      "Episode: 1519/5000, score: 207\n",
      "Episode: 1520/5000, score: 167\n",
      "Episode: 1521/5000, score: 229\n",
      "Episode: 1522/5000, score: 172\n",
      "Episode: 1523/5000, score: 464\n",
      "Episode: 1524/5000, score: 499\n",
      "Episode: 1525/5000, score: 499\n",
      "Episode: 1526/5000, score: 398\n",
      "Episode: 1527/5000, score: 146\n",
      "Episode: 1528/5000, score: 196\n",
      "Episode: 1529/5000, score: 346\n",
      "Episode: 1530/5000, score: 152\n",
      "Episode: 1531/5000, score: 142\n",
      "Episode: 1532/5000, score: 153\n",
      "Episode: 1533/5000, score: 162\n",
      "Episode: 1534/5000, score: 149\n",
      "Episode: 1535/5000, score: 142\n",
      "Episode: 1536/5000, score: 163\n",
      "Episode: 1537/5000, score: 154\n",
      "Episode: 1538/5000, score: 205\n",
      "Episode: 1539/5000, score: 144\n",
      "Episode: 1540/5000, score: 392\n",
      "Episode: 1541/5000, score: 177\n",
      "Episode: 1542/5000, score: 209\n",
      "Episode: 1543/5000, score: 289\n",
      "Episode: 1544/5000, score: 230\n",
      "Episode: 1545/5000, score: 173\n",
      "Episode: 1546/5000, score: 285\n",
      "Episode: 1547/5000, score: 148\n",
      "Episode: 1548/5000, score: 162\n",
      "Episode: 1549/5000, score: 153\n",
      "Episode: 1550/5000, score: 191\n",
      "Episode: 1551/5000, score: 362\n",
      "Episode: 1552/5000, score: 349\n",
      "Episode: 1553/5000, score: 145\n",
      "Episode: 1554/5000, score: 121\n",
      "Episode: 1555/5000, score: 184\n",
      "Episode: 1556/5000, score: 177\n",
      "Episode: 1557/5000, score: 24\n",
      "Episode: 1558/5000, score: 124\n",
      "Episode: 1559/5000, score: 294\n",
      "Episode: 1560/5000, score: 224\n",
      "Episode: 1561/5000, score: 461\n",
      "Episode: 1562/5000, score: 125\n",
      "Episode: 1563/5000, score: 170\n",
      "Episode: 1564/5000, score: 183\n",
      "Episode: 1565/5000, score: 217\n",
      "Episode: 1566/5000, score: 323\n",
      "Episode: 1567/5000, score: 168\n",
      "Episode: 1568/5000, score: 401\n",
      "Episode: 1569/5000, score: 173\n",
      "Episode: 1570/5000, score: 242\n",
      "Episode: 1571/5000, score: 499\n",
      "Episode: 1572/5000, score: 163\n",
      "Episode: 1573/5000, score: 311\n",
      "Episode: 1574/5000, score: 128\n",
      "Episode: 1575/5000, score: 190\n",
      "Episode: 1576/5000, score: 255\n",
      "Episode: 1577/5000, score: 154\n",
      "Episode: 1578/5000, score: 289\n",
      "Episode: 1579/5000, score: 230\n",
      "Episode: 1580/5000, score: 288\n",
      "Episode: 1581/5000, score: 122\n",
      "Episode: 1582/5000, score: 162\n",
      "Episode: 1583/5000, score: 158\n",
      "Episode: 1584/5000, score: 499\n",
      "Episode: 1585/5000, score: 183\n",
      "Episode: 1586/5000, score: 149\n",
      "Episode: 1587/5000, score: 164\n",
      "Episode: 1588/5000, score: 499\n",
      "Episode: 1589/5000, score: 434\n",
      "Episode: 1590/5000, score: 139\n",
      "Episode: 1591/5000, score: 113\n",
      "Episode: 1592/5000, score: 115\n",
      "Episode: 1593/5000, score: 364\n",
      "Episode: 1594/5000, score: 238\n",
      "Episode: 1595/5000, score: 345\n",
      "Episode: 1596/5000, score: 132\n",
      "Episode: 1597/5000, score: 165\n",
      "Episode: 1598/5000, score: 499\n",
      "Episode: 1599/5000, score: 16\n",
      "Episode: 1600/5000, score: 172\n",
      "Episode: 1601/5000, score: 159\n",
      "Episode: 1602/5000, score: 265\n",
      "Episode: 1603/5000, score: 413\n",
      "Episode: 1604/5000, score: 164\n",
      "Episode: 1605/5000, score: 499\n",
      "Episode: 1606/5000, score: 149\n",
      "Episode: 1607/5000, score: 173\n",
      "Episode: 1608/5000, score: 122\n",
      "Episode: 1609/5000, score: 131\n",
      "Episode: 1610/5000, score: 128\n",
      "Episode: 1611/5000, score: 156\n",
      "Episode: 1612/5000, score: 142\n",
      "Episode: 1613/5000, score: 187\n",
      "Episode: 1614/5000, score: 152\n",
      "Episode: 1615/5000, score: 306\n",
      "Episode: 1616/5000, score: 238\n",
      "Episode: 1617/5000, score: 122\n",
      "Episode: 1618/5000, score: 122\n",
      "Episode: 1619/5000, score: 167\n",
      "Episode: 1620/5000, score: 230\n",
      "Episode: 1621/5000, score: 176\n",
      "Episode: 1622/5000, score: 244\n",
      "Episode: 1623/5000, score: 282\n",
      "Episode: 1624/5000, score: 327\n",
      "Episode: 1625/5000, score: 308\n",
      "Episode: 1626/5000, score: 219\n",
      "Episode: 1627/5000, score: 499\n",
      "Episode: 1628/5000, score: 342\n",
      "Episode: 1629/5000, score: 130\n",
      "Episode: 1630/5000, score: 139\n",
      "Episode: 1631/5000, score: 271\n",
      "Episode: 1632/5000, score: 140\n",
      "Episode: 1633/5000, score: 173\n",
      "Episode: 1634/5000, score: 139\n",
      "Episode: 1635/5000, score: 126\n",
      "Episode: 1636/5000, score: 128\n",
      "Episode: 1637/5000, score: 148\n",
      "Episode: 1638/5000, score: 124\n",
      "Episode: 1639/5000, score: 118\n",
      "Episode: 1640/5000, score: 124\n",
      "Episode: 1641/5000, score: 144\n",
      "Episode: 1642/5000, score: 133\n",
      "Episode: 1643/5000, score: 297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1644/5000, score: 131\n",
      "Episode: 1645/5000, score: 131\n",
      "Episode: 1646/5000, score: 158\n",
      "Episode: 1647/5000, score: 153\n",
      "Episode: 1648/5000, score: 268\n",
      "Episode: 1649/5000, score: 155\n",
      "Episode: 1650/5000, score: 224\n",
      "Episode: 1651/5000, score: 227\n",
      "Episode: 1652/5000, score: 178\n",
      "Episode: 1653/5000, score: 214\n",
      "Episode: 1654/5000, score: 268\n",
      "Episode: 1655/5000, score: 192\n",
      "Episode: 1656/5000, score: 136\n",
      "Episode: 1657/5000, score: 131\n",
      "Episode: 1658/5000, score: 174\n",
      "Episode: 1659/5000, score: 170\n",
      "Episode: 1660/5000, score: 258\n",
      "Episode: 1661/5000, score: 133\n",
      "Episode: 1662/5000, score: 191\n",
      "Episode: 1663/5000, score: 167\n",
      "Episode: 1664/5000, score: 129\n",
      "Episode: 1665/5000, score: 131\n",
      "Episode: 1666/5000, score: 186\n",
      "Episode: 1667/5000, score: 108\n",
      "Episode: 1668/5000, score: 260\n",
      "Episode: 1669/5000, score: 298\n",
      "Episode: 1670/5000, score: 170\n",
      "Episode: 1671/5000, score: 246\n",
      "Episode: 1672/5000, score: 366\n",
      "Episode: 1673/5000, score: 400\n",
      "Episode: 1674/5000, score: 244\n",
      "Episode: 1675/5000, score: 212\n",
      "Episode: 1676/5000, score: 207\n",
      "Episode: 1677/5000, score: 280\n",
      "Episode: 1678/5000, score: 230\n",
      "Episode: 1679/5000, score: 141\n",
      "Episode: 1680/5000, score: 168\n",
      "Episode: 1681/5000, score: 179\n",
      "Episode: 1682/5000, score: 140\n",
      "Episode: 1683/5000, score: 118\n",
      "Episode: 1684/5000, score: 244\n",
      "Episode: 1685/5000, score: 499\n",
      "Episode: 1686/5000, score: 207\n",
      "Episode: 1687/5000, score: 138\n",
      "Episode: 1688/5000, score: 172\n",
      "Episode: 1689/5000, score: 180\n",
      "Episode: 1690/5000, score: 132\n",
      "Episode: 1691/5000, score: 383\n",
      "Episode: 1692/5000, score: 165\n",
      "Episode: 1693/5000, score: 134\n",
      "Episode: 1694/5000, score: 158\n",
      "Episode: 1695/5000, score: 128\n",
      "Episode: 1696/5000, score: 163\n",
      "Episode: 1697/5000, score: 144\n",
      "Episode: 1698/5000, score: 499\n",
      "Episode: 1699/5000, score: 199\n",
      "Episode: 1700/5000, score: 173\n",
      "Episode: 1701/5000, score: 226\n",
      "Episode: 1702/5000, score: 128\n",
      "Episode: 1703/5000, score: 129\n",
      "Episode: 1704/5000, score: 128\n",
      "Episode: 1705/5000, score: 147\n",
      "Episode: 1706/5000, score: 151\n",
      "Episode: 1707/5000, score: 132\n",
      "Episode: 1708/5000, score: 242\n",
      "Episode: 1709/5000, score: 168\n",
      "Episode: 1710/5000, score: 254\n",
      "Episode: 1711/5000, score: 267\n",
      "Episode: 1712/5000, score: 375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e3b73bcc2e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CartPole-v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mq_dnn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mQNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mq_dnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-d28bf1eec3c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m#extra_reward = 1.0/abs(next_state[2]) + 1.0/abs(next_state[3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d28bf1eec3c3>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m#print('Action ',predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m#print('Predicted ',np.argmax(predict))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d28bf1eec3c3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \"\"\"\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4083\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4084\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4085\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m-> 1096\u001b[0;31m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[0m\u001b[1;32m   1097\u001b[0m             raise ValueError(\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "q_dnn= QNN(env)\n",
    "q_dnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-11 00:15:10,011] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01779243  0.04391646 -0.0282028   0.00472075]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "print(env.reset())\n",
    "state, reward, end, _ = env.step(0)\n",
    "img = env.render(mode='rgb_array')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0169141 , -0.15078991, -0.02810838,  0.28837364])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def position(state):\n",
    "    screen_width = 600\n",
    "    world_width = 2.4* 2\n",
    "    scale = screen_width / world_width\n",
    "    pos = int(state[0] * scale + screen_width / 2.0)\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALMAAAD8CAYAAAA8GpVKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT3IpnoaAWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129055b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "pos = position(state)\n",
    "new_img = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY)\n",
    "new_img = new_img[160:320,pos-50:pos+50]\n",
    "#new_img = cv2.resize(new_img,(64,64))\n",
    "plt.imshow(new_img, cmap='gray')\n",
    "print(new_img.shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_two, reward, end, _ = env.step(0)\n",
    "img_two = env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c8fb5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "pos = position(state)\n",
    "new_img_two = cv2.cvtColor(np.asarray(img_two), cv2.COLOR_BGR2GRAY)\n",
    "new_img_two = new_img_two[160:320,pos-50:pos+50]\n",
    "new_img_two = cv2.resize(new_img_two,(64,64))\n",
    "plt.imshow(new_img_two-new_img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((4,4))\n",
    "a = a.reshape(4,4,1)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((4,4))\n",
    "b[0]=8\n",
    "b = b.reshape(4,4,1)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u=np.concatenate((a, b), axis=2)\n",
    "u = u.reshape(1,4,4,2)\n",
    "print(u[0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def train(self):\n",
    "        interactions = 500\n",
    "        state_size = self.env.observation_space.shape[0]\n",
    "        with self._session.as_default() as sess:\n",
    "            self.init.run()\n",
    "        end = False\n",
    "        max_iterations = 0\n",
    "        for e in range(self.episodes):\n",
    "            obs = self.env.reset()\n",
    "            state = self.env.render(mode='rgb_array')\n",
    "            state = self.state_transformation(obs[0],state)\n",
    "            next_state = self.env.render(mode='rgb_array')\n",
    "            next_state = self.state_transformation(0,next_state)\n",
    "            for iteration in range(500):\n",
    "                action = self.select_action(state)  \n",
    "                obs, reward, end, _ = env.step(action)\n",
    "                extra_reward = 1.0/abs(obs[2]) + 1.0/abs(obs[1])\n",
    "                pix  = self.env.render(mode='rgb_array')\n",
    "                next_state = self.state_transformation(obs[0],pix)\n",
    "                reward = reward #+ extra_reward\n",
    "                #if end:\n",
    "                #    reward = - 100\n",
    "                self.remember_transition(state, action, reward, next_state, end)\n",
    "                state = next_state \n",
    "                if end:\n",
    "                    print(\"Episode: %d/%d, score: %d\" % (e, self.episodes, iteration))\n",
    "                    if iteration > max_iterations:\n",
    "                        max_iterations = iteration \n",
    "                    break\n",
    "\n",
    "            if len(self.memmory) > self.batch_size:\n",
    "                self.experience_learing()\n",
    "    \n",
    "\n",
    "        print(\"Best Number of Iterations: %d\" % (max_iterations))\n",
    "        \n",
    "        with self._session.as_default() as sess:\n",
    "            self.saver.save(sess, \"./openai_convolution.ckpt\")  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "\n",
    "class DeepQNN:\n",
    "    '''\n",
    "    episodes - NUMBER OF GAMES\n",
    "    gamma - discount rate\n",
    "    epsilon - exploration rate\n",
    "    epsilon_decay - decrease the number of explorations\n",
    "    epsilon_min - lower epsilon\n",
    "    lr - learning rate\n",
    "    '''\n",
    "    def __init__(self, env, episodes = 5000 , gamma = 0.95, epsilon = 1, epsilon_decay=0.9, epsilon_min=0.05, lr=0.001, random_state=42):\n",
    "    \n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.lr = lr\n",
    "        self.random_state = random_state\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.env = env\n",
    "        self.batch_size = 75\n",
    "        self.episodes = episodes\n",
    "        self.model_params = None\n",
    "        \n",
    "        self.activation_fn = tf.nn.elu\n",
    "        self.weights_initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "        self.optimizer = tf.train.AdamOptimizer\n",
    "        \n",
    "        self._graph = None\n",
    "        self._session = None\n",
    "        self.training_op = None\n",
    "        self.model = None\n",
    "        self.init = None\n",
    "        self.saver = None\n",
    "        \n",
    "        # Memory used for replaying actions\n",
    "        '''\n",
    "        using this memory improve stability. NN tends to forget previous actions learned, so the memory\n",
    "        allows a esxperience replay\n",
    "        '''\n",
    "        self.memmory = deque()\n",
    "        \n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        self.build_dnn()\n",
    "            \n",
    "    def build_dnn(self):\n",
    "        #Reset Tensorflow Graph\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            n_conv_filters = 32\n",
    "\n",
    "            X = tf.placeholder(tf.float32, shape=(None, 160, 100, 1),name= 'state')\n",
    "            y = tf.placeholder(tf.float32, shape=(None), name='quality')\n",
    "            self._X, self._y = X, y\n",
    "            self.training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "            conv_one = tf.layers.conv2d(X,filters= 4, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv1\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_one = tf.layers.batch_normalization(conv_one, training=self.training, momentum=0.9)\n",
    "            #conv_one = tf.nn.relu(conv_one)\n",
    "            \n",
    "            conv_two = tf.layers.conv2d(conv_one, filters= 2, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv2\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_two = tf.layers.batch_normalization(conv_two, training=self.training, momentum=0.9)\n",
    "            #conv_two = tf.nn.relu(conv_two)\n",
    "            \n",
    "            conv_three = tf.layers.conv2d(conv_two ,filters= 2, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv3\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_three = tf.layers.batch_normalization(conv_three, training=self.training, momentum=0.9)\n",
    "            #conv_three = tf.nn.relu(conv_three)\n",
    "            \n",
    "            \n",
    "            conv_four = tf.layers.conv2d(conv_three ,filters= 2, kernel_size=2, strides=1,\n",
    "                                    padding= \"SAME\", name=\"conv4\"\n",
    "                                   ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_four = tf.layers.batch_normalization(conv_four, training=self.training, momentum=0.9)\n",
    "            #conv_four = tf.nn.relu(conv_four)\n",
    "            \n",
    "            conv_five = tf.layers.conv2d(conv_four, filters= 2, kernel_size=4, strides=1,\n",
    "                                   padding= \"SAME\", name=\"conv5\"\n",
    "                                  ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_five = tf.layers.batch_normalization(conv_five, training=self.training, momentum=0.9)\n",
    "            #conv_five = tf.nn.relu(conv_five)\n",
    "            \n",
    "            conv_six = tf.layers.conv2d(conv_five, filters= 2, kernel_size=4, strides=1,\n",
    "                                   padding= \"SAME\", name=\"conv6\"\n",
    "                                  ,kernel_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "            \n",
    "            #conv_six = tf.layers.batch_normalization(conv_six, training=self.training, momentum=0.9)\n",
    "            #conv_six = tf.nn.relu(conv_six)\n",
    "            \n",
    "            flat = tf.reshape(conv_five , shape=[-1, 2 * 160 * 100])\n",
    "            #with tf.name_scope(\"pool\"):\n",
    "            #    pool = tf.nn.max_pool(conv_two, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "            #   pool_flat = tf.reshape(pool, shape=[-1, n_conv_filters * 32 * 32])\n",
    "\n",
    "            with tf.name_scope(\"fc\"):\n",
    "                fc1 = tf.layers.dense(flat, 6, name=\"fc1\"\n",
    "                                      , kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                #fc1 = tf.layers.batch_normalization(fc1, training=self.training, momentum=0.9)\n",
    "                #fc1 = tf.nn.elu(fc1)\n",
    "            \n",
    "                #fc1 = tf.layers.dropout(fc1, 0.5, training = self.training)\n",
    "                fc2 = tf.layers.dense(fc1, 6, activation=tf.nn.elu,name=\"fc2\"\n",
    "                                      ,kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                #fc2 = tf.layers.batch_normalization(fc2, training=self.training, momentum=0.9)\n",
    "                #fc2 = tf.nn.elu(fc2)\n",
    "            \n",
    "                #fc2 = tf.layers.dropout(fc2, 0.5, training = self.training)\n",
    "                \n",
    "                fc3 = tf.layers.dense(fc2, 6, activation=tf.nn.elu,name=\"fc3\"\n",
    "                                      ,kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                #fc3 = tf.layers.batch_normalization(fc3, training=self.training, momentum=0.9)\n",
    "                #fc3 = tf.nn.elu(fc3)\n",
    "                # Dense with linear activation function\n",
    "                self.model = tf.layers.dense(fc2, self.n_actions,name=\"fc4\"\n",
    "                                            ,kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "            with tf.name_scope(\"train\"):\n",
    "                loss = tf.losses.huber_loss(self._y, self.model)\n",
    "                optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "                #loss = tf.losses.mean_squared_error(self._y, self.model)\n",
    "                #loss = tf.reduce_mean(tf.squared_difference(x=self.model,y=self._y))\n",
    "                #optimizer = tf.train.AdamOptimizer(0.001)\n",
    "                self.training_op = optimizer.minimize(loss, name = \"training\")\n",
    "\n",
    "            with tf.name_scope(\"init_and_save\"):\n",
    "                self.init = tf.global_variables_initializer()\n",
    "                self.saver = tf.train.Saver()\n",
    "            \n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "       \n",
    "            \n",
    "    def remember_transition(self,state, action, reward, new_state, end):\n",
    "        \n",
    "        self.memmory.append((state, action, reward, new_state, end))\n",
    "        \n",
    "    def minibatch_sample(self):\n",
    "        return random.sample(self.memmory, self.batch_size)\n",
    "    \n",
    "    def predict(self,state):\n",
    "        with self._session.as_default() as sess:\n",
    "            return self.model.eval(feed_dict={self._X: state, self.training:False})\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_actions)\n",
    "        predict = self.predict(state)[0]\n",
    "        return np.argmax(predict)\n",
    "\n",
    "    def experience_learing(self):\n",
    "\n",
    "        minibatch = random.sample(self.memmory, self.batch_size)\n",
    "        for state, action, reward, next_state, end in minibatch:\n",
    "            target = reward\n",
    "            if not end:\n",
    "                target = reward + self.gamma * np.amax(self.predict(next_state)[0])\n",
    "            target_f = self.predict(state)[0]\n",
    "            target_f[action] = target         \n",
    "\n",
    "            with self._session.as_default() as sess:\n",
    "                sess.run(self.training_op, feed_dict={self._X: state, self._y: target_f, self.training: True})\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        '''\n",
    "    \n",
    "        states = self.minibatch_sample()\n",
    "        inputs = np.zeros((self.batch_size, 64, 64, 1))\n",
    "        targets = np.zeros((self.batch_size, self.n_actions))\n",
    "        for i in range(len(states)):\n",
    "            state = states[i][0]\n",
    "            action = states[i][1] \n",
    "            reward = states[i][2]\n",
    "            new_state = states[i][3]\n",
    "            end = states[i][4]\n",
    "            # Bellman equation\n",
    "            inputs[i: i+1] = state\n",
    "            quality = reward + self.gamma * np.amax(self.predict(new_state)[0])\n",
    "            if end:\n",
    "                quality = reward\n",
    "            targets[i] = self.predict(state)\n",
    "            targets[i][action] = quality\n",
    "            \n",
    "        with self._session.as_default() as sess:\n",
    "            sess.run(self.training_op, feed_dict={self._X: inputs, self._y: targets, self.training: True})\n",
    "            \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "                \n",
    "    '''\n",
    "    def combine(self, current_frame, new_frame, pos):\n",
    "        \n",
    "        current_frame = cv2.cvtColor(np.asarray(current_frame), cv2.COLOR_BGR2GRAY)\n",
    "        #current_frame =  current_frame.reshape(current_frame.shape[0],current_frame.shape[1],1)\n",
    "        new_frame = cv2.cvtColor(np.asarray(new_frame), cv2.COLOR_BGR2GRAY)\n",
    "        #new_frame = new_frame.reshape(new_frame.shape[0],new_frame.shape[1],1)\n",
    "        \n",
    "        #comb = np.concatenate((new_frame, current_frame), axis=2)\n",
    "        comb = new_frame - current_frame \n",
    "        \n",
    "        pos = self.position(pos)\n",
    "        min_pos = pos - 50\n",
    "        max_pos = pos +50\n",
    "        if min_pos < 0:\n",
    "            min_pos = 0\n",
    "            max_pos = 100\n",
    "        if max_pos > 600:\n",
    "            min_pos = 500\n",
    "            max_pos = 600\n",
    "        \n",
    "        comb = comb[160:320,min_pos:max_pos]\n",
    "        #comb = cv2.resize(comb,(64,64))\n",
    "        #_, comb[:,:,0] = cv2.threshold(comb[:,:,0],200,255,cv2.THRESH_BINARY)\n",
    "        #_, comb[:,:,1] = cv2.threshold(comb[:,:,1],200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "        return comb.reshape(1,160,100,1)\n",
    "        \n",
    "        \n",
    "    def diff_frames(self, current, past):        \n",
    "        diff = cv2.cvtColor(np.asarray(current-past), cv2.COLOR_BGR2GRAY)\n",
    "        return diff\n",
    "    \n",
    "    def position(self,pos):\n",
    "        screen_width = 600\n",
    "        world_width = 2.4* 2\n",
    "        scale = screen_width / world_width\n",
    "        pos = int(pos * scale + screen_width / 2.0)\n",
    "        return pos\n",
    "        \n",
    "    def state_transformation(self, pos, img):\n",
    "        '''\n",
    "        state = scipy.misc.imresize(state,(64,64))\n",
    "        r,g,b = state[:,:,0], state[:,:,1], state[:,:,2]\n",
    "        bw = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return bw.reshape(1,64,64,1)\n",
    "        '''\n",
    "        img = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY)\n",
    "        pos = self.position(pos)\n",
    "        min_pos = pos - 50\n",
    "        max_pos = pos +50\n",
    "        if min_pos < 0:\n",
    "            min_pos = 0\n",
    "            max_pos = 100\n",
    "        if max_pos > 600:\n",
    "            min_pos = 500\n",
    "            max_pos = 600\n",
    "       \n",
    "        img = img[160:320,min_pos:max_pos]\n",
    "        #img = cv2.resize(img,(64,64))\n",
    "        _, img = cv2.threshold(img,200,255,cv2.THRESH_BINARY)\n",
    "        return img.reshape(1,160,100,1)\n",
    "        \n",
    "    \n",
    "    def get_model_params(self):\n",
    "        gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "    def restore_model_params(self, model_params):\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\") for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n",
    "        \n",
    "    def train(self):\n",
    "        interactions = 500\n",
    "        state_size = self.env.observation_space.shape[0]\n",
    "        with self._session.as_default() as sess:\n",
    "            self.init.run()\n",
    "        end = False\n",
    "        max_iterations = 0\n",
    "        for e in range(self.episodes):\n",
    "            obs = self.env.reset()\n",
    "            state = self.env.render(mode='rgb_array')\n",
    "            #state = self.state_transformation(obs[0],state)\n",
    "            next_state = self.env.render(mode='rgb_array')\n",
    "            #next_state = self.state_transformation(0,next_state)\n",
    "            comb = self.combine(state, next_state, obs[0])\n",
    "            \n",
    "            #plt.figure()\n",
    "            #plt.imshow(comb[0,:,:,0], cmap='gray')\n",
    "            #plt.show()\n",
    "            \n",
    "            for iteration in range(500):\n",
    "                action = self.select_action(comb)  \n",
    "                obs, reward, end, _ = env.step(action)\n",
    "                extra_reward = 1.0/abs(obs[2]) + 1.0/abs(obs[3])+ 1.0/abs(obs[1])\n",
    "                next_state  = self.env.render(mode='rgb_array')\n",
    "                next_comb = self.combine(state, next_state, obs[0])\n",
    "                #next_state = self.state_transformation(obs[0],next_state)\n",
    "                reward = reward + extra_reward\n",
    "                if end:\n",
    "                    reward = -1\n",
    "                self.remember_transition(comb, action, reward, next_comb, end)\n",
    "                state = next_state\n",
    "                comb = next_comb\n",
    "                if end:\n",
    "                    print(\"Episode: %d/%d, score: %d\" % (e, self.episodes, iteration))\n",
    "                    if iteration > max_iterations:\n",
    "                        max_iterations = iteration \n",
    "                    break\n",
    "\n",
    "            if len(self.memmory) > self.batch_size:\n",
    "                self.experience_learing()\n",
    "    \n",
    "\n",
    "        print(\"Best Number of Iterations: %d\" % (max_iterations))\n",
    "        \n",
    "        with self._session.as_default() as sess:\n",
    "            self.saver.save(sess, \"./openai_convolution.ckpt\")  \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
